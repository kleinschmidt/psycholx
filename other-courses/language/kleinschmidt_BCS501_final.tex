\documentclass[11pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{apacite}
\usepackage{setspace}

\doublespacing


\begin{document}

\section*{BCS 501 Language, final exam \\ Dave Kleinschmidt}

\section*{1. Speech perception}
\label{sec:1.-speech-perception}

%1. Discuss the evidence from speech perception concerning whether speech is special.  Then go on to discuss how phonetic categories of a particular language may be acquired from the initial auditory or linguistic capabilities with which the system begins. 

One major source of evidence for the early speech-is-special position comes from the phenomenon of categorical perception.  When asked to label sounds on a phonetic continuum where some acoustic parameter is manipulated in physically equally-sized steps, listeners' phonetic percept changes abruptly at some point in the middle of the continuum, rather than shading gradually from one category to the next.  Moreover, human listeners can make finer acoustic discriminations when the two stimuli straddle such a phonetic cateogry boundary then when the stimuli belong to the same category.  

Such categorical perception is known to be language-specific (i.e.,is not present for category boundaries that are not part of the listener's native language, such as /l/-/r/ for Japanese listeners, \citeNP{Kuhl2004}).  On the basis of this evidence, it was believed that humans perceive speech using a specialized perceptual mode, where fine-grained distinctions are thrown away early in perceptual processing in favor of a symbolic, categorical code.

However, work with animals showing very similar patterns of categorical perception in Chinchillas (down to the specific boundary locations for voiced categories and context-independent voicing categories; \citeNP{Kuhl1978}) makes it seriously unlikely that these behavioral patterns are enough to conclude that speech is perceived in a special way from the very earliest stages.  Moreover, work in visual perception shows that learned (and even linguistic) categories can have large effects in very low-level tasks like visual search and detection \cite{Lupyan2010,Lupyan2008}.

The non-specialness of speech has serious implications for theories of speech acquisition which rely on universal and innate perceptual mechanisms which convert acoustic cues into discrete features.  In such a model, the seemingly intractable complexity of the task of acquiring speech categories is reduced to simply detecting which featural distinctions are relevant in the learner's native language.  However, recent work has demonstrated that from a very early age, abilities are in place that subserve a more domain-general learning mechanism.

First, very young infants appear to be ``universal listeners'', distinguishing phonemes from any language, suggesting that phonetic categories are aligned to the properties of the human (or mammalian) auditory system \cite{Kuhl2004}.  Second, infants are sensitive to distributional statistics of acoustic parameters, and can use such information to infer categorical distinctions based on very limited evidence, modulating their looking behavior depending on whether they are exposed to a bimodal or unimodal distribution of acoustic cues \cite{Maye2002}.  Third, infants from a young age can take advantage of statistical regularities in the form of transitional probabilities which can be used to segment continuous speech, along with prosodic features that infants are also sensitive to.

Modeling work suggests that very general statistical inference of the kind discussed above can infer actual phonetic categories based on realistic distributions of acoustic parameters, making use of sequential statistics to acquire perceptually difficult distinctions.  These models do not (in principle) rely on the assumption of known segmentation or word boundaries; to take one example, \citeA{Feldman2009} demonstrated that phonetic and lexical categories (English vowels, and words) could be learned simultaneously from unlabeled sequences of acoustic values.


\pagebreak
\section*{2. Spoken word recognition}
\label{sec:2.-spoken-word}

%2. Classic models of spoken word recognition claim lexical access takes place against a set of multiple lexical candidates that compete for recognition. Describe and evaluate the evidence in support of these notions. Has recent evidence for sensitivity to fine-grained information and rapid perceptual learning/adaptation altered that picture, and if so, how? 

The cohort model of Marslen-Wilson is the classic model of parallel access in spoken word recognition.  It posits that bottom-up information about the identity of the word is incrementally matched against words in the lexicon, such that as information about each segment of the word becomes available, the set of active candidates is reduced to only those words whose initial segments match the segments of the input.  

Evidence for this model comes from the fact that point in a word at which subjects make a recognition response (the ``recognition point'') is highly correlated with that word's uniqueness point (the position in the word where there are no more cohort competitors as determined by a phonetic dictionary). The recognition point can be measured directly, via a gating task where subjects hear successively longer initial sub-intervals of the spoken word until they are able to recognize it.  It can also be measured indirectly, based on responses to a phoneme-monitoring task using multi-syllable words.  Subjects use a lexical strategy in such tasks, often responding before they have actually heard the target phoneme (which can occur quite late in the word; \citeNP{Marslen-Wilson1987}).  Reaction times in such a task are highly correlated with the uniqueness point of the word, rather than the position of the target phoneme (as is the case when the target segment is embedded in a non-word).

Activation of cohort competitors can also be inferred based on cross-modal priming data.  In such a task, a subject has to perform a visual task (such as lexical decision) while listening to a putatively-unrelated spoken sentence.  Cross-model priming refers to the fact that subjects are faster to process visual words that are related to recently heard spoken input.  When the visual target is presented before the uniqueness point of the spoken prime (before the second vowel of \textsc{captain}, when \textsc{captive} is still in the cohort), reaction times to semantic associates of both cohort members are faster (\textsc{ship} and \textsc{guard}).  However, when the target is presented at the end of the word (when it is unambiguously identified), only \textsc{ship}, the associate of the actual prime \textsc{captain}, is primed \cite{Marslen-Wilson1987}.

More recent work supports the cohort model's general idea that spoken word recognition involves many different lexical items competing for selection, but requires a more nuanced view on the nature of this competition and the way that the competitor set is constructed.  First of all, evidence for visual-world eye-tracking studies reveals that, in addition to showing above-chance looks to cohort competitors (as predicted by the cohort model), listeners also look more to rhyme competitors, which are \emph{not} in the cohort of the target and thus should not be considered under the cohort model.

Moreover, subjects consider not only the identity of segments in the input, but also fine-grained, sub-phonetic detail.  Subjects look more at voiced competitors for VOTs which are shorter than prototypical for voiceless stops (but still classified as voiceless), and vice-versa, and even when they make the appropriate identification response subjects take longer to fixate the target for less-prototypical VOT values.  The time course of neighborhood-density effects shows early facilitatory effects, which arise from the combination of the tendency of high-density words to be shorter and the presence of fine-grained cues to word length early in the word \cite{Magnuson2007}.

Thus, words are not categorically included or excluded from the set of activated competitors based on the presence or absence of particular segments.  Instead, the competitor set must instead be considered a dynamic profile of activity (or probability mass) distributed over the whole lexicon based on fine-grained goodness-of-fit measures, as in exemplar models of word recognition \cite<e.g.>{Goldinger1998}.  Individual segments, though, do play a role in word recognition, since different distributions of segment-specific cues like VOT influence looking behavior even on unambiguous cue values \cite{Clayards2008}.  These two facts leave the relevance of phoneme recognition to whole word recognition somewhat uncertain, although the presence or absence of a phoneme could be considered simply another (not perfectly-reliable) cue to word identity.

\pagebreak
\section*{3. Syntactic processing}
\label{sec:3.-synt-proc}

%3. Compare structure-first models of syntactic processing with constraint-based models and expectancy-driven (surprisal) models. What are the major discrepancies among these classes of theories? What is the evidence for one of these types of models over the other? What types of further evidence would you want to see to evaluate these approaches?

Structure-first theories postulate that syntactic processing occurs in two stages: an initial, incremental structure-building stage that relies only on the syntactic categories of the input words and a small number of simple heuristics (e.g. minimal attachment), and a later re-analysis stage, should the initial parse turn out to not match the input.  In this view, memory constraints limit the number of possible parses that can be considered simultaneously, as well as the variety of information which can be used to construct the most likely parse the first time around.  These theories are supported by data showing that subjects experience reading difficulty at the first place where a non-minimally-attached reading is required.

Constraint-based theories, however, treat syntactic processing as a single process of parallel constraint satisfaction, where the syntactic parse is constructed, incrementally, using all available information, including not only the syntactic categories of words but also their subcategorization biases, fine-grained phonetic features, relation to the discourse context, etc.  These models posit that garden path effects are not categorically different, but rather a point on a continuum of difficulty or consistency of cues, with difficulty arising from the need to resolve competition between competing parses associated with the lexically-specific biases of the verb and the later input.  Constraint-based theories are supported by evidence that lexically specific factors like subcategorization bias or thematic fit modulate the comprehension difficulty of ambiguous sentences, as does discourse context.

Expectation-based models like that of \citeA{Levy2008} represent an attempt to generalize and reconcile these theories.  They broadly consider parsing difficulty to reflect violation of expectations (which requires the re-ranking of candidate parses), while remaining neutral as to the exact mechanisms and sources of information which are engaged to generate these expectations.  Like constraint-based models, such a model can (potentially) consider lexically-specific biases and discourse factors.  Like structure-first models, they focus on the allocation of scarce resources as a bottleneck for comprehension difficulty.

\citeA{Levy2008} uses the surprisal of each word in context (which is closely related to the degree of candidate parse re-ranking necessary) as a measure for its difficulty in incremental comprehension.  Evidence for expectation-based model comes from findings that structural ambiguity and long dependencies can be helpful, contrary to the predictions of competition-based accounts (like constraint-based theories, generally) on the one hand, and structural complexity-based account (like Dependency Locality Theory and minimal attachment) on the other.

One potential sticking point for expectation-based models is the question of the level at which expectations are generated and the sorts of information which is drawn on to generate them.  Part of the appeal of such models is the precise quantification of word-by-word comprehension difficulty from probabilistic language models, but work showing that discourse context and referential fit influences difficulty necessitates that such factors---which are external to standard PCFG-style language models---need to be included in a comprehensive theory of comprehension difficulty.  

Finally, in order to explain the facilitatory effect of ambiguity, the pure surprisal model of \citeA{Levy2008} requires that comprehenders maintain full, essentially infinite distribution over possible parses, or some good approximation.  It is important to determine empirically how many parses can be considered simultaneously, in which situations multiple parses are simultaneously considered, and modeling-wise, what sort of strategies are able to approximate this behavior (via rich lexical representations, or multi-scale chunking of exemplars, a la \citeNP{Arnon2010}).


\pagebreak
\section*{4. Syntactic choice in production}
\label{sec:4.-syntactic-choice}

%4. Contrast availability-based approaches and uniform-information density approaches to explaining the problem of syntactic choice in production.

There are many ways to communicate a message linguistically, but this flexibility is not arbitrary or limitless, and any theory of language production in general and syntactic encoding in particular must explain why one form is chosen, on average, in one situation while another form might be preferred in another.  Such systematic patterns show up in the form of, for instance, phrase ordering, the presence or absence of the optional complementizer \emph{that}, double object/prepositional phrase alternation, left-dislocation and topicalization, and bi-clausal vs. mono-clausal forms.

Approaches to language production can be divided into two broad classes, the product tradition and the action tradition.  The product tradition treats the linguistic utterance as primarily the end result of an encoding process, which takes a pre-linguistic message and selects linguistic forms to convey that message.  This tradition explains syntactic choice by appealing to factors like availability, which correspond to the state of the encoding system.  The principle of availability dictates that syntactic forms are chosen such that more available information is produced earlier, giving the encoding system more time to retrieve and encode more difficult phrases.

The action tradition treats the linguistic utterance itself as a means to an end, emphasizing communication of intent or coordination of joint action between conversational partners.  As a corollary to this perspective, it follows that the speaker should distribute effort over their utterances in such a way as to maximize the clarity of the message.  This idea is captured computationally in the principle of uniform information density, which posits that whenever a choice of syntactic form is available, the form which best spreads information over the whole utterance should be chosen.

Availability-based and UID approaches both explain the fact that optional ``that'' is included more often in more complex or less predictable sentences.  Optional ``that'' can buy more time to encode a complex complement clause (availability), or it could function as a signal to the upcoming complexity and decrease the average information content of each word in the sentence (UID).

However, these two approaches can be distinguished in situations where word order and grammatical feature assignment is the same.  Such a situation was analyzed by \citeA{Gallo2008}, who examined mono-clausal vs. bi-clausal forms (``Take the apple and put it in Central Park'', vs. ``Take the apple.. Put it in Central Park'').  Availability-based theories make no predictions about which of these two forms will be preferred when grammatical feature assignment and word order are the same, while UID predicts that the bi-clausal form will be preferred in situations where the theme (``apple'') is more complex or less predictable (and thus carries more information).  This is in fact exactly what was found in a corpus of instructions in a cooperative game \cite{Gallo2008}.

A further distinction can be made between the way that the two accounts treat disfluencies.  In the product tradition, disfluencies are a side effect of production difficulty, while in the action tradition they are a collateral cue to complexity or production difficulty, like relativizer presence.  Indeed, in the Switchboard corpus of conversational speech, relativizer presence is correlated with disfluency rate.  This holds even when controlling for potential sources of production difficulty, which suggests that speakers use both the relativizer ``that'' and disfluencies to cue upcoming production difficulty.



\pagebreak
\section*{9. }
\label{sec:7-9.-choose}

A new paradigm in language research has emerged, which treats language use and acquisition as a process of statistical inference. This paradigm is inspired in equal parts by experimental work showing language use and acquisition to be sensitive to probabilistic and distributional information and advances in computational models of statistical models of structured knowledge.  On the theoretical end, the statistical language paradigm treats observable cues, intermediate linguistic representations, and facts about the world as probability distributions.  Language comprehension is inference of meanings (possibly linguistic representations) given observable cues (linguistic and otherwise) \cite<e.g.,>{Norris2008,Levy2008}, and acquisition is inference of categorical structure given un-structured input and some minimal ``scaffolding'' \cite<e.g.,>{Feldman2009,Xu2007,Kemp2008}.

This paradigm is closely related to connectionist approaches to language.  It emphasizes domain-general learning mechanisms, sensitivity to the rich, latent structure present in linguistic input, and a minimal amount of innate explicit knowledge about language structure.  Moreover, in many cases there is a clear trajectory from connectionist models of language to statistical models \cite<e.g.,>{Norris2008}.  Much of the success of connectionism was due to the revelation that structure could be extracted from unlabeled data using powerful general-purpose learning mechanisms, mechanisms which approximate statistical inference.  

Connectionist approaches a la \citeA{Seidenberg1997}, however, suffer from a lack of interpretability: the linchpins of neural network computation, the hidden units, defy any meaningful interpretation, as does the network as a whole which has learned a particular task.  This makes it very hard to interpret the success of a connectionist model at a particular task, other than as simply a proof of concept or negative finding (``explicit representations of type X are unnecessary for task Y'').  Additionally, the input and output representations of connectionist models are often arbitrary, and the use of backpropagation learning makes neural networks biologically implausible, negating the natural mechanistic interpretation of artificial neurons as analogous to real neurons.  This puts connectionist theories on weak footing both from a computational perspective and an implementation perspective.

Statistical models have the benefit of transparent relationships between the input and output, and admit interpretable intermediate representations without a loss of computational power.  This makes such models more directly relevant to non-computational theories, even while their nature as (generally) computational-level models makes them more removed from questions of particular mechanisms or processes.

The statistical perspective on language provides a good complement to psycholinguistic work showing adaptation to recent linguistic experience at many levels.  At the level of syntax, subjects show better comprehension of object relative clauses \cite{Wells2009} and sentence-complement continuations of ambiguous sentences \cite{Garnsey1997} after limited exposure.  Subjects also show changes in phonetic classification after exposure to acoustically ambiguous segments disambiguated by lexical \cite{Norris2003} or visual \cite{Vroomen2007} information, and even after exposure to distributions of VOT values with different variance \cite{Clayards2008}.  Such effects are both rapid \cite{Fine2010,Kraljic2005} and long-lasting \cite{Fine2011,Eisner2006}, and, critically, are well-described by rational statistical models \cite{Fine2010,Kleinschmidt2011}.  

Rational analyses of adaptation are closely related, in spirit, to the usage-based and lifelong implicit learning traditions, in that all of these approaches seek to connect learning and processing.  Statistical models, though, additionally offer an explanation of \emph{why} integrating learning and processing is useful for the language system: good prediction of upcoming events minimizes processing effort, and the best predictions are made when the agent's prior expectations are in line with the actual statistics of the environment.  Statistical models additionally clarify the distinction between the learning that happens during usage and that during acquisition (which is famously hard to replicate in second-language learning during adulthood).  Acquisition is a process of inferring structure, which requires more evidence and suffers from interference in an adult system where the underlying grammatical structure of the language has been stable for the entire development of the agent.

Work in non-linguistic visual and auditory perception, as well as multimodal cue combination has similarly focused on perception as statistical inference.  A combination of computational work on the statistics of natural scenes and neurophysiological work on the response properties of individual neurons and neural populations has shown that the visual and auditory systems are adapted to the statistical properties of natural scenes \cite{Olshausen1996,Lewicki2002,Rodriguez2010}.  Similar work on multisensory perception and cue combination shows that both humans and non-human animals combine information from multiple sources in a way that is statistically optimal \cite{Alais2004,Ernst2002,Morgan2008}.  Beyond simply bringing language science into better alignment with work in other fields, the particular nature of the continuous-to-discrete mapping of language perception has pushed models of cue combination beyond the simple, non-categorical tasks used in earlier work \cite{Bejjanki2011,Toscano2010}.

While the statistical perspective on language provides substantial insight into existing data on language use and acquisition, it is of course important to acknowledge its horizon.  At its heart statistical theories of language are pitched at the computational level \cite{Marr1982}, concerning the sort of information-processing functions entailed without much consideration for the particular mechanisms which carry out those functions.  This puts it at odds with much previous work which seeks to establish facts that are most relevant to precisely the implementational level which statistical models have the least to say about (for now).

The objection that this fact makes statistical models wrong (or worse, irrelevant) can be met in two main ways.  First, the main competing paradigms, connectionism and symbolic-representationalism, are both at their hearts computational-level models, picking out different classes of input-output mapping functions based on their natural formal properties (those which can be expressed as distributed, parallel computation on the one hand, and those which are expressed as formal operations over symbolic representations on the other).  Implementational interpretations follow at a later stage, as for the statistical paradigm they no doubt will, and in fact cognitively plausible interpretations of formally intractable Bayesian inference are beginning to be explored \cite<e.g.,>{Sanborn2010,Shi2010,Ma2006}.  Second, computational analysis, even though they don't strongly constrain lower levels of analysis, can help formulate new hypotheses about plausible implementations and algorithms; see, for example, the growth of psycholinguistics work based on attempts to validate ultimately flawed predictions of generative syntax.  In the context of statistical models of cognition generally, Bayesian statistics provides a normative standard for optimal behavior, from which human behavior ultimately deviates.  However, this does not mean that such normative models are worthless.  Rather, if the normative model is externally motivated, then deviations from optimality point directly to constraints imposed by the mechanism by which the optimal inference is approximated.  I believe that this provides the best potential for cashing out the predictions of language-as-inference models pitched at the computational level, when combined with work on how such inference can be approximated in ways that are neurally plausible.








\pagebreak
\singlespacing
\bibliographystyle{apacitex}
\bibliography{/Users/dkleinschmidt/Documents/papers/library.bib}

\end{document}
