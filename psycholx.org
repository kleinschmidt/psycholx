#+TITLE: Grad psycholinguistics
#+STARTUP: indent contents

* Scheduling

whenisgood: t748bj http://whenisgood.net/ywa7dkt/results/t748bj2
http://whenisgood.net/ywa7dkt

* structure
a few weeks on "foundational" stuff: speech perception, sentence processing,
production?, pragmatics

** organizational meeting
  
** what is language and why psycholx
  
** speech perception
categorical perception/continuous perception

might also require introduction to the speech signal itself (for non-ling
folks).

** spoken word recognition
   
   
** Sentence processing
garden path sentences, ambiguity, parsing

DLT?  classical parsing (content free) vs. lexical/constraint satisfaction
models (MacDonald stuff?)
   
** production
speech errors, sentence production too?

** pragmatics/discourse
RSA vs. traditional models?  or even more basic...

** sociolx
"three waves" of sociolx; 

** Info theory
syntax: levy/smith and levy

word structure (piantadosi stuff)

** noisy channel models
how/why are these distinct from purely "bayesian"/ideal observer models?
thinking about the production stuff and the Ryskin paper on learning the
noise model...

** learning and adaptation
lots of stuff here...

** speaker specific representations
I'm thinking both the long-term memory stuff in speech and the Kamide work on
high/low attachment preferences, maybe also informativity

** structured vs. structure free
examplar models vs abstractionist

** variation and structure (and maybe sociolx?)
what kind of structure is there?  (chodroff, tanner, my LCN paper)

* Preliminary schedule
** 2020-09-01 Organizational meeting
** 2020-09-10 What and why
** 2020-09-17 Speech perception
** 2020-09-24 Spoken word recognition 
** 2020-10-01 Sentence processing 
** 2020-10-08 Production 
** 2020-10-15 Pragmatics/discourse 
** 2020-10-22 Sociolx 
** 2020-10-29 Learning and adaptation 
** 2020-11-05 Talker specificity 
** 2020-11-12 Bayesian theories 
** 2020-11-19 Information theory 
** 2020-11-27 NO CLASS (thanksgiving)
** 2020-12-01 Noisy channel models 
** 2020-12-08 (Final presentations)
* topics/theme
I think the overall theme is going to be variability vs. structure.  How much
do these affect processing?  How are they each represented?  What are the
computational demands they each pose?

Then there are the "classic" debates in psycholx: parsing wars, interactive
activation vs. feedforward, prediction.

The other big question is how foundational vs. "what I'm interested in now" to
make this.  More and more I'm leaning towards foundational (it'll correct some
of the things that are missing in Sten and Joselyn's preparation and probably
be more useful/interesting for the others...).  But putting together a reading
list is a little harder there I guess, so...  Maybe the first few weeks are
going to be "basic stuff you need to know" and the last few weeks will be
special topics?  I dunno.

what's the point of this class?  what are these students going to get out of
it?  they're all graduate students.  not all of them are studying language,
but many of them are.
  
** continuous vs. discrete  
e.g. categorical perception, graded grammaticality

** top-down vs. bottom-up processing
** exemplar models

** availability vs. info theory models (production) 

** stability vs. plasticity

** parsing wars: structure or content?
** methods
eye tracking, corpus, psychophysics, self-paced reading, computational
modeling

especially interesting angle might be behavioral methods...how is language
processing reflected in BEHAVIOR?  what are the relevant behviors and what do
we know about them?  What kind of information can we hope to get from
language-related behavior?  What's the time/spatial/social scale at which
we're studying this behavior?
   
** acquisition (related to stability/plasticity?)

** what information is used when 
modularity vs. interaction.  perspective taking.  socio stuff.  prediction
vs. integration.

** role of context
   
** is speech/language special?
to what extent can speech processing be explained by general auditory
mechanisms?

* other classes
  
** BCS 501 (chigusa and mike version 2017)
[[https://docs.google.com/spreadsheets/d/1rQjU2_a6jeoXle8hGFT93jem8XidXOs6dUcungDXz-A/edit#gid=1386834576][Schedule and readings]] [[https://docs.google.com/spreadsheets/d/1WaMJ0N-7XvIcpCCY56_dwVd-XRVJD4nhOsgHngh4nic/][(my copy)]]

They spent first 8 classes on foundational stuff...lots of reading from the
oxford handbook plus some supplemental stuff.  Then 6 classes on more current
stuff I guess.

It's a very "mike and chigusa" flavored set of topics...lots of spoken word
recognition, information structure

I guess I don't necessarily need to cover exactly the same material since the
language people are all in my/karin's lab.  but I think some depth is going
to be really important.
** BCS 501 (chigusa and mike 2015 version)
2x weekly, much more of a survey.

** BCS 501 (Mike's lang class)
This was pretty basic or introductory from what I remember...or rather,
foundational.  There was a lot of reading.  No syllabus but I have the emails
with readings/topics 

*** week 1
Chomsky, N. (l980). Rules and representations.  The Behavioral and Brain
Sciences, 3(1), 1-15.

Miller, G.A. ( l965). Some preliminaries to psycholinguistics.  American
Psychologist, 20(1), 15-20.

Miller, G.A. (l990). The place of language in a scientific psychology. In G.A.

Miller (Ed.), Psychological Science, 1(1), 7-14.

Seidenberg, M. (1997) Language acquisition and use: Learning and applying
probabilistic constraints.  Science, 275, 1599-1603.

Hauser, M. D., Chomsky, N., &amp; Fitch, W. T. (2002). The faculty of language:
What is it, who has it, and how did it evolve? Science, 298, 1569-1579.

*** week 2

*** week 3? dick aslin guest lecture
probably something about speech...I have the slides 

*** (missing week)
*** sentence processing

Frazier, L. (1987).  Sentence processing: A tutorial review.  In
M. Coltheart (Ed.), Attention and Performance.  Hillsdale, NJ: Lawrence
Erlbaum Associates.

Gibson, E. (2002).  Linguistic complexity in sentence processing.  In Oxford
Encyclopedia of Cognitive Science

Marslen-Wilson, W.  (1973).  Linguistic structure and speech shadowing at
very short latencies.  Nature, 244, 522-523.

Marslen-Wilson, W.  (1975).  Sentence perception as an interactive parallel
process.  Science, 189, 226-228.

Levy R. (2008) Expectation-based sentence processing.  Cognition
    
Tanenhaus, M.K. & Trueswell, J.C.  (1995). Sentence comprehension.  In:
J.L. Miller & P.D. Eimas (Eds.). Handbook of perception and cognition
Vol. 11: Speech, language and communication, 217-262.  San Diego, CA:
Academic Press.

*** sentence production
Griffin, Z. M. (2003). A reversed word length effect in coordinating the
preparation and articulation of words in speaking. Psychonomic Bulletin and
Review, 10(3), 603-609.

Ferreira, V. (1996).  Is it better to give than to donate? Syntactic
flexibility in language production.  Journal of Memory and Language, 35, 724-755
    
Dell et al. (2008) Saying the right thing at the right time


*** perspective taking?
Wardlow Lane et al. (2006) Don't Talk about Pink Elephants!

Keysar et al. 2000 Taking Perspective in Conversation
*** lissa (development)

Lenneberg, E.H.  (1969).  On explaining language: The development of
language in children can best be understood in the context of developmental
biology.  Science, 164, 635-643.

Gleitman, L.R., & Newport, E.L. (1995).  The invention of language by
children: Environmental and biological influences on the acquisition of
language.  In L.R. Gleitman and M. Liberman (Eds.), An Invitation to
Cognitive Science, 2nd ed.  Vol 1: Language.  Cambridge, MA: The MIT Press.

Newport, E.L.  (2002).  Critical periods in language development.  In
L. Nadel (Ed.), Encyclopedia of Cognitive Science.  London: Macmillan
Publishers Ltd./Nature Publishing Group.

Optional: Pinker, S. & Prince, A.  (1988). On language and connectionism:
Analysis of a parallel distributed processing model of language acquisition.
Cognition, 28, 73-193.]

Newport, E.L., & Aslin, R.N. (2000). Innately constrained learning: Blending
old and new approaches to language acquisition. In S. C. Howell, S. A. Fish,
and T. Keith-Lucas (eds.), Proceedings of the 24th Annual Boston University
Conference on Language Development.  Somerville, MA: Cascadilla Press.

Marcus, G., Vijayan, S., Bandi Rao, S., & Vishton,
P. M. (1999). Rule-learning in seven-month-old infants, Science, 283, 77-80.

Aslin, R.N. & Newport, E.L. (2011).  Statistical learning: From acquiring
specific items to forming general rules.  Current Directions in
Psychological Science, in press.
*** visual world
*** adaptation
(maybe this is from teh LSA institute?)
** Lang and Cog
could do like an advanced version of this?
** my own quals
psycholx section has some foundational stuff too...

* meetings 

** week 0 - organizational

*** Agenda
Scheduling

Syllabus

Work and grading

Final project

Topics

*** Tuesday 12:30
Meet next week?

** week 1 - what/why
   
*** Planning
    
**** Questions for discussion
Does the performance/competence distinction still matter?  What role did it
play in the historical development of psychology/cognitive science?

How important is communication in understanding language?  Is language
"for" communication, or something else?

Can language /behavior/ tell us anything about linguistic /knowledge/?
Conversely, is it possible to study language /without/ studying linguistic
behavior?

Why might language as Chomsky saw it be a challenge for behaviorism?

How does the idea of innate linguistic knowledge ("universal grammar") fit
with our current understanding?  What role does it play in current thinking
in the field of formal/Chomskian linguistics?  What about
psycholinguistics?

Many of these papers make a contrast (explicitly or implicitly) between
/statistical/ models and /grammatical/ models of linguistic knowledge.  Are
these really in opposition?  Why or why not?

Psychology and cognitive science have gone through a number of periods
where different conceptions of what a good theory reigned.  What's the
current paradigm in your area?  How is this period going to look in the
light of history?

**** Introductory topics

"Scruffies and neats": "Roger Schank actually notes that he originally made
this distinction in linguistics, related to Chomskian vs. non-Chomskian,
but discovered it works in AI too, and other areas. " [[https://en.wikipedia.org/wiki/Neats_and_scruffies][(wiki)]]

Marr's levels of analysis?

Language /structure/ vs. language /content/; grammar vs. statistics

pendulum swings: stastical/surface vs. structural/deep

Basics of linguistics: performance vs. competence

     
***** history
History of modern cognitive science/psychology; behaviorism and the
cognitive revolution; the advent of connectionism

evolution of the idea of /universal grammar/: from very specific
structural knowledge to...recursion

degree of interest in (different kinds of) behavior
      
***** themes
Draw your attention a a couple of high-level topics and themes that tie
these papers together.

1. What language is /for/: communication, representation, something else?
   (Related to the evolutionary origins of language and the nature of
   linguistic knowledge)
2. Linguistic /knowledge/ vs. linguistic /behavior/ (competence
   vs. performance)
3. The role of statistical/probabilistic information in language
   processing and in linguistic knowledge (is the grammar probabilistic?)

**** what's the plan
the idea for this week is to situate psycholinguistics in the broader
context of the field of psychology, and linguistics (and cognitive science,
more broadly).

So we read papers that try to give a concise overview of (some of) the
history of cognitive science and the role of language in that (Miller), and
some foundational issues in what we mean when we talk about language
(communication, Hockett; grammar, HCF; statistical knowledge, Seidenberg)

There's also this narrative that Chomsky is single-handedly responsible for
dismantling the dominant behaviorist paradigm in his review of Skinner's
/Verbal Behavior/; the Miller papers place that in a slightly broader
context as well, as one part of the cognitive revolution in psychology
which was well underway by the time Chomsky was writing that.

**** yea but what are we going to DO during class
discuss readings ... use them as jumping off point to talk about bigger
issues (see questions above)

**** order to topics

***** Miller (history)

***** Hockett; HCF; Seidenberg

** week 2 - speech
   
*** Readings
handbook chapters: Gaskell plus Pisoni & Levi.

**** Pisoni and Levi
Argue that encode BOTH abstractions AND details of specific instances

3 basic assumptions of "traditional approaches":

1. set of discrete and linear symbols to represent continuous speech
2. symbols are "abstract, static, invariant, and context-free"
3. psychological processes "normalize" acoustic differences

   Problems with the traditional view: non-linearity of the acoustic signal
   (coarticulation/smearing); lack of (acoustic-phonetic) invariance;
   segmentation is hard.  Many of these spring from a *bottom-up* approach to
   speech recognition (sounds → phonemes → words).

***** Evidence for specificity in speech encoding
Mullennix et al. (1989): intelligibility lower and repetition slower in
multi-talker lists

Mullenix & Pisoni (1990): attend to words slowed by voice variabiltiy, and
vice-versa (but easier to ignore word variability than voice)

Specific voice details encoded in recognition memory (even with lots of
talkers), up to a week

Speaking rate variation affects identification, but not amplitude.

Speaking rate variation also affect recall memory (primacy)

Nygaard et al. (1994): novel word recognition easier for familiar voices
than unfamiliar

Allen and Miller (2004): speaker-specific VOT dists, generalize to unheard
words.

***** 

**** Gaskell
Some confusion about the different models, that's understandable.
      

*** Questions for discussion
    
**** What makes a representation "abstract"? 
see Sten's response paper...also Huteng.  Is "abstract" vs. "episodic"
really the best way to think about the tradeoff here?

also Joselyn: talking about degree of abstractness in layers in TRACE.

**** What Marr level do exemplar/episodic theories target?

**** Tradeoff between number/granularity of representations and processing
Normalization/compensation for context is necessary to reach something like
an abstract, context-free symbolic representation.  Exemplar models avoid
this by just storing enough relevant context to make normalization
un-necessary, but this massively increases the amount of possible
representations in your system...

what's the benefit/cost of each approach?

**** why did it take so long?
most of the ref's in the Pisoni & Levi chapter about the problems for the
"traditional view" are from the *1950s*!!
 
**** exemplar models and "coupling between ... prior experiences" and current processing
     
**** what is the evidence for exemplars?

**** what is the evidence for abstractions?

**** what's noise and what's signal
from Joseph's paper: each extra source of variation makes local
interpretation more difficult, but maybe together they make GLOBAL
interpretation easier?
     
*** Material for context
    
**** categorical perception
     
**** "lack of invariance"
coarticulation and talker variabiltiy are two big ones
**** Different types of models

***** "Traditional" (abstractionist) models
have something like a "template" for each phoneme/allophone in your
language.  compare the speech stream to these templates to get
phonemes/allophones, then that is input into symbolic processing in the
phonological grammar.

***** IAC
TRACE as an example

***** distributed connectionist models
not really clear on these here...I guess this is the DCM, which uses an
SRN to take in phonetic features and output "a distributed representation
of lexical content"

***** statistical models
I think they're talking about like n-gram models here.

***** exemplar models
episodic version: store detailed, un-analyzed acoustic traces in memory
(think: raw spectrogram).  phonolgical representations emerge from
similarity-based retrieval.

**** relations between model families
"connectionist models" are a big tent: include "localist" models like
TRACE, "distributed" models like DCM

** Week 3 - lexical access
   
*** Readings

**** Marslen-Wilson 1989
Lexicon links *form* and *content*, two kinds of processing, "access" and
"integration"
     
Interpretation is continuous and immediate

What's the relationship between form and content based processing?  Early
selection in context (before form is enough) suggests that selections
guided by content too

This is *fast* so it has to be happening in parallel (both access and
"assessment", comparison to contextual constraints)

(cohort model: how is this different from e.g. TRACE?  one big one: no
mutual inhibition between active words)

/contingency of perceptual choice/ in the cohort model: "outcome and timing
of the selection process are determined by the properties of the /complete
ensemble/ of perceptual possibilities open to the listener".  (selection
happens when you have a winner, which depends on who else is playing)

"Cues to any individual phonetic segment are distributed over time, and, in
particular, they overlap with cues to adjacent segments" (p. 9)

gating task: 25ms gates...free response.  place of articulation AND final
stop voicing (vowel duration) both show continuous access.

directionality: initial mismatch rules out items?  compare cross-model
priming for cohort overlap (ambig, presented mid word, vs. end of word, when
it's not ambiguous), and rhyme overlap work/nonword (complete).  Find no
priming for rhyme overlap, despite similar amounts of overlapping material
as with onset (but I think TRACE et al. can still explain this?)

parallel activation of semantic content: cross-modal form based priming
([kapit] primes "boot" (boat) and "geld" (money))

what's the role of context?  pre-selection?  argues against this: effects
of context in a cross-modal priming task only show up once you reach the
uniqueness point of the prime word, even in highly-constraining contexts.

there's a puzzle here though: in an actual gating task with the same
stimuli, you can identify the final word much earlier than the point at
which cross-modal priming effects seem to kick in.  argues that priming is
basically a lexical effect, whereas the integration is happening..somewhere
else?  hard to say.
     
overall comes down on the side of lexical access being a *Fodorian input
system* (primacy of the bottom-up input).

**** McQueen 2007
     
     
**** Comparison
MW focuses mostly on the bottom-up information...primacy of the signal.

One point of contrast is that there's a lot more nuance in the McQueen
summary when it comes to *mismatch*: MW basically just says if there's a
mismatch then that's bad (does he?  does he also talk about sub-categorical
mismatch?)
     
Evidence that rhyme-overlap are also considered discussed in McQueen
(p. 42).

*** things from response papers
**** Ryne
what's the relation with these papers and the "traditional" level from
papers last week?  Seems like these authors are both taking the traditional
view...

recognition point vs. uniqueness point

**** Huteng
Doesn't cite any phonologists...

What is the cohort model, really?  What is the gating technique?

**** Yarkin
segmental vs. suprasegmental information...can they really be separated?

**** Joseph
relate these to predictive models like GPT and SRN...(to me, interesting
question is how much and what kind of context are involved in capturing the
predictions people seem to be making?)

*** Questions

If content/context influences form-based selection in lexical access, how
could the models we discussed last week account for that?  What kind of
predictions would that make?

Integration vs. prediction ("true" top-down vs. "only integration"
effects)...how can you tell them apart?  What are the readings suggesting
about that?

Let's look critically at the assertion from Marslen-Wilson that the
bottom-up signal has primacy in lexical access in light of the more recent
findings summarized by McQueen (coarticulation, assimilation, use of
phonological knowledge, context effects)

What about the claim of directionality?  What's the evidence for this?  Are
there alternative explanations for these findings?

Are any of these effects /incompatible/ with an exemplar model?  Are any of
them easier/more natural to explain with an exemplar model than a
"abstractionist" model where lexical access is mediated by sublexical
representations?  (Maybe the suprasegmental stuff, like the "'ham' in
'hamster'" effect...)

*** Learning goals for this week     
Identify the methodologies that are used to investigate lexical access in
these papers (cross-modal priming, gating, word identification)

Think about the relationship between the *cognitive processes and
representations* as distinct from the *methods* we use to probe them (e.g.,
word identification shows early use of context information, but cross-model
priming does not).
    
Be able to explain how we know that word forms and meanings are activated in
/parallel/ during lexical access.

Think about the role of top-down processing in lexical access.  Does it play
any role?  What is the role?  What sort of information is involved in
top-down lexical access?

(related to above) We're starting to approach how context across different
levels of linguistic processing might affect speech recognition.  Based on
these readings, what is the role that context can and cannot play in lexical
access?

How has our understanding of lexical access evolved between the two
readings?  (More detailed understanding of what information matters and how
much, rather than just match/mismatch; expanded scope of study to
segmentation and suprasegmental cues like stress)  What hasn't changed?
("primacy of the signal")
    
*** Plan for class
Want to do a bit more structured stuff...like having pairs come up with
answers to basic content questions, put them in a shared google doc, and
then report back to the whole class.
    
**** themes
interaction between bottom-up and top-down information.  

continuous and probabilistic access and integration.

lexical access sensitive to many many sources of information.

**** activities
***** methods (15 minutes)
make a list of the main methods discussed in these readings.  

***** what's the evidence for parallel activation of word FORMs and MEANINGs (30 minutes)
Form: priming to onset matches; disruption of lexical access when a changed
segment makes another word but not (or less so) for a nonword.  fast access
(close shadowing)

recognition point (based on neighbors); early entry; recognize similar
sounding words based on onsets

Meaning: cross-model priming of onset matches.  involvement of context in
identification before uniqueness point.
     
***** what role does top-down processing play in lexical access? (60 minutes?)
Are there limits?  What is the evidence?

My take: MW argues it plays a /limited role/: shows up in /integration/
processes but not in activation/access/selection.  Evidence for this is:
recognition before uniqueness point, but limited because you don't get
context-specific priming /until uniqueness point/ (context-inconsistent
but form-consistent words are still considered)  (questions about
"activatoin" and "spreading activation" metaphor here)

questions (Ryne and Yarkin): what counts as "top-down"

Sten and Elif: what is lexical access here? (bug example).  WHYYY woudl
you activate the other meanings if you can rule them out???  (uncertainty
about segmentation?  uncertainty about context?)

phonemic restoration?

***** representations: gradient/categorical
compatible with exemplar models?  with "traditional view"?  with
connectionist models like TRACE?

think especially about the findings reviewed in McQueen: importance of
suprasegmental cues, coarticulation, gradedness.

McQueen starts by just assuming that lexical access is mediated by some
kind of sub-lexical categorical representations...how consistent is that
with the results he reviews?

**** Groups from class
Prompt 1: Huteng, Joselyn, Joseph; Ryne, Yarkin; Elif, Sten

** Class 4 - sentence processing
    
*** Readings

**** Tanenhaus and Trueswell

*I think this reading is too hard* - not enough details/examples, too much
literature is reviewed. it's VERY THOROUGH but ... hard to grasp for someone not
already familiar with the paradigms etc.

Contrast is between /constraint based/ vs. /informationally encapsulated/
(modular) theories.

***** History
general arc: language as product (sentence as a linguistic entity) to language
as action (situated in discourse context, produced and interpreted online and
continuously)

Miller - deep structure + transformation tags stored in memory.

***** Current issues

****** Syntactic category ambiguity
multiple access - different senses are activated even in constraining contexts
(but sentence context only weakly constraining), rapidly resolved based on
semantic and syntactic context.  /contingent frequencies/

****** Attachment ambiguity
three families of theories: garden path, referential, and constraint-based.

garden path: Minimal Attachment (simplest possible parse) and Late Closure
(prefer to attach to recent material if equally simple parse)

Referential theories: multiple parses in parallel, selected based on /pragmatic
fit/ with discourse model.  "weakly interactive" (disdcourse model doesn't
affect the generation of parses, but does influence initial selection).  what
/presuppositions/ are required to resolve referring expressions?  syntactic and
presuppositional complexity oftren related (in null context: "the pupil spotted"
read as RC requires presupposing a SET of pupiles, as MV only one)

Constraint-based: underspecified (besides "context/frequency matters"),
frequency hard to compute given lack of large corpora.  lexicalist theories
change that: donate example.  explain reduced relative ambiguity via various
lexical ambiguities (argument structure; tense; voice).  "The horse raced past
the barn fell" vs. "The landmine buried in the sand exploded" (race/bury
frequency in passive/participle/intransitive, agent-ness of horse/landmine)

******* Evidence
disambiguating region: hgiher reading times (first and second pass)

verb-specific syntactic frames ("After the child visited/sneezed the doctor
prescribed...") - rapid filtering of initial parse or constraint based...effects
of frequency (base rate of structure vs. verb-specific bias)

thematic fit/argument assignment: animacy of subject doesn't affect initial
attachment...but they do in more constraining contexts (etc.); and thematic
effects for reduced relatives (stronger for verbs common in passive participle)

referential context: does impact parsing but doesnt' determine it...depends on
sentence local factors that determine the availability of the syntactic
alternatives

prosody and intonation: it matters (phrase boundaries)

****** empty categories
Filler-gap dependencies.  Why?  Because syntactic theories care about them, and
different syntactic theories differ in how they handle them.  Also about
coordinating different kinds of information (for the less ling-y crowd).

Early proposal: filler held in memory until gap is encountered (ERP evidence and
concurrent memory task).  Strong bias to fill first gap that can.

Similar debate: do lexical factors or purely category based factors matter when
determining whether gap filling candidate is good?

Gaps (empty categories) appear to prime like pronouns do (maybe even at the
point the verb is encountered)

****** sentence memory
evidence that there's no verbatim memory even for recent material, "reconstructed
out of lexical representations and their argument structures"

but...priming.

****** context and anaphora
not a separate stage where context-independent meaning is
computed/extracted... rather interpretation happens in the context of a
discourse model shaped by context and continuously updated as new material comes
in.

lots of different linguistics forms taken by anaphors (referring expressions).

"deep" vs. "surface" anaphors (Sag and Hankamer) - hypothesis was that surface
is /linguistic/ representation vs. /conceptual or discourse/ for deep.  (surface
places form constraints, requires linguistically specified antecedent).  but not
much experimental support ... conceptual reference for deep anaphor yes, but
also for surface...

**** van Gompel and Pickering (2007)
both classes are theory are alive and well 10+ years later!  Still work being
done on "revision"

thematic fit is weak (pro-modular) but discourse information is fast
(pro-constraint).

the rest I ... skipped

un-grammatical parses are still stored in memory/affect later parsing?
e.g. kashak and glenburg finding (ungrammatical form gets easier to comprehend);
the thing about changing the baby

*** Questions
What's the advantage of a "garden path" model of online sentence processing?
(Simple rules, informationally encapsulated; theory is more constrained so makes
more specific predictions, vs. constraint-based theories which suffer
underspecification)

How do the three families of theories explain processing difficulty (in
e.g. attachment ambiguity)

Evidence for garden path model?  (Processing difficulty in disambiguating region,
eye movement evidence)

What is the source of difficulty in these models?  (Revision, re-ranking,
conflicting constraints)

One thing that's interesting to me here is the different stakes for the debates
on different sides...like whether semantics can OVERRIDE syntax, or just
influence it quickly.  does semantics CONSTRAIN initial syntactic analysis or
just influence it?

big take away here: there's LOTS OF FACTORS that might affect processing speed
and difficulty, and many of them do matter.  But also many of them are HIGHLY
CORRELATED with each other.  So, what does this tell us about the nature of 1)
language and 2) the language processing system?

what if anything does formal linguistic theory play in our understanding of
sentence processing?

relationship between incremental processing and parallel activation and
ambiguity...do you HAVE to have parallel consideration of multiple
parses/words/etc. when speech comes in online?  If you don't, what kind of
serial processing is compatible with the demands of the continuous input?  what
kind of constraints does the basic 'design principle' of language place on the
processing, and how far can we get just by looking at those constraints?

why is there ambiguity at all?  seems like a bad design choice!

(related: written vs. spoken stimuli, does that bias our understanding?)

What things are /easy/ to explain with a garden path theory, and what things are
/hard/?  What about constraint satisfaction?  What theoretical problems do these
theories /solve/, and what do they /create/?  Garden path theories - solve the
problem of fast, online comprehension (information encapsulation, simple
procedures)...create the problem of how other information gets integrated

*** response papers

**** Ryne
"Kind of fun that you can add components/attachments to your model ad hoc and
everyone’s got different models/principles with names (e.g. Fodor & Frazier
adding Late Closure)." lolololol

**** Joselyn
"what's a sentence and why do we focus on it..."

multiple languages

**** Joseph
modular/interactive - belief updating...reliability of evidence, bias-variance
tradeoff

temporal stuff, does it matter in bayesian updating? 

**** Sten
lexical vs. syntactic ambiguity resolution

no bayes (but foreshadowing??)

*** Learning objectives
Identify the problems these theories are trying to explain (language unfolds
over time and is processed /rapidly/ and /continuously/, but has a
hierarchical/nonlinear structure/"nonadjacent grammatic dependencies" which
leads to /temporary ambiguity/ during processing)

Identify the major empirical /phenomena/ and methods addressed in this work
(high level: "who did what to whom" kind of parsing, (self-paced) reading
time/difficulty/, memory of surface form,

Identify the different theories of syntactic ambiguity resolution:
modular/garden path, interactive/constraint satisfaction, (maybe: discourse
model...what's this called?)

Garden path theory: identify the stages of processing in garden path theories,
and when different kinds of evidence play a role in parsing? (Syntactic category
and grammar, first pass.  Thematic fit/semantics, only on encountering error)

Identify major sources of empirical evidence IN FAVOR of garden path theories,
and AGAINST (reading times slower at disambiguating regions; evidence that
frequency and thematic fit can influence early processing)

Identify the relationship between /linguistic theory/ and /psycholinguistic/
investigation (turn from deep structure to surface structure/clausal
processing, etc.)

Connect the theories of parsing this week with the issues of lexical access we
discussed last week: what role does top-down information play in parsing
according to garden path + constraint satisfaction theories?  When is it
available, and when is it used?  (Garden path model is /kind of/ like the cohort
model...except that cohort model allows ambiguity to be resolved based on top
down information...)

Connect debates in parsing with larger issues of how multiple, correlated
constraints/cues shape processing...does that fact make it EASIER or HARDER to
extract the underlying linguistic structure of the speech stream?  (on the one
hand, it makes it easier because there's many sources of evidence to guide your
interpretation, but harder because they're not all directly/locally linked to
the underlying structure, and they're /weak/ or /probabilistic/ sources of
evidence...)

*** Plan
Same as last week, use breakout rooms and a google doc with prompts for
reflection.  Aim for 3-4 topics/questions to discuss

We have 180 minutes of class time...plan on 20 minutes for break/late start
etc. so that's 160.

**** Prompt 1: theories - 30 minutes (5+10+15)
For modular vs. interactive theories, /what information/ is used to construct the
parse, and /when/ is it used?

- modular: syntactic categories (N/V/Adj/P) + grammatical rules at first (as
  words come in), lexical information/frequency/thematic fit only when the
  initial syntactic parse fails
- interactive: anything and everything...thematic fit (how "agent-y" a noun is),
  subcategorization frames, argument structure, frequency information.  all
  information is /available/, but some information only actually ends up being
  /used/ when there's no stronger cues available (e.g., bottom-up syntactic
  category/grammatical restriction

What is the source of /processing difficulty/ in these theories?

**** Prompt 2: empirical evidence - 45 minutes (0+20+25)
What is the evidence reviewed in the readings that best supports (or supported
at the time) the garden-path theory?  What about constraint-based interactive
theory?  Try to identify 2-3 pieces of evidence for each.

- modular: Joseph (memory for ungrammatical initial), reading times at
  disambiguating region for bad structure
- constraint satisfaction

**** break - 20 minutes

**** Prompt 3: Compare and contrast with lexical access theories - 30 minutes (5+10+15)
Last two weeks we discussed how sounds make contact with linguistic
representations and the lexicon - the "traditional view", connectionist theories
like TRACE, the cohort model, exemplar theory.

Which of these approaches do you see as closest in spirit with the garden-path
theory?  The 'constraint satisfaction' theory?

- garden path: traditional view...strict separation of information sources?
- constraint satisfaction theory: cohort model maybe, but generation of cohort
  is purely bottom-up...but TRACE

I'm hearing...information encapsulation, what's considered when...
**** Prompt 4: Many correlated cues - remainder of class
Again, connect with last week: McQueen especially highlights how many different
sources of information there are in the speech signal to guide lexical access,
cues which people do appear to use.  With the readings this week, we're again
seeing that: there are many overlapping "constraints" or cues which guide the
listener/reader to the correct parse of a sentence (or lead them astray).

What does this fact about the /structure of language/ suggest about the language
processing systems?  E.g., does the existence of such overlapping cues make
processing /easier/ or /harder/ for the system?

What does the empirical evidence about whether (or when) people seem to make use
of different kinds of constraints/cues/information tell us about the nature of
language processing?

**** Prompt 5: what is the role of linguistic theory here?
(I see two places: historical development of psycholinguistic theory/models, and
in identifying linguistically interesting or important phenomena to target with
psycholinguistics, like null anaphor/gapping/ellipsis)

** Class 5 - production

*** Readings

**** Goldrick - Connectionist theories

***** Initial notes
A "generic localist" connectionist network for speech production (word naming),
explains three types of empirical phenomena: mixed errors more common than
expected by chance, semantic interference vs. phonological facilitation, and
impairments.

Then turns to talking about distributed theories, and learning.  Focus on
syntactic priming as implicit learning (Chang et al. , SRN with learning
mechanism), and some kinda oscillator based distributed representation of
sequencing/planning of phonetic segments (lost on me)

***** close reading
mixed errors: explained via two additional mechanisms (cascading activation
and/or feedback)...

disruptions: global vs. local explanations (local wins, global cannot account
for "pure" error distributions, like only semantic)...original global account
has two free parameters: (global) connection weight scaling and (global) decay.
fit to 21 aphasic patients, predict rate of
semantic/phonological/unrelated/non-word errors.

production models *dffer* from connectionist principle in other domains, in two
ways: no learning, and localist representations  (connected: backprop learning
yields distributed hidden layer representations).  two recent developments
1. syntactic priming as implicit learning
2. distributed representations of planning frames using oscillators with learned
   connection weights to phonological structure (interesting that they do not go
   into the problems with the localist representations of words!!)

***** learning objectives
two stages: activation and selection.  why two stages?  what's the role that
each plays?  what's the mechanism for each?  (spreading activation; boosting,
competitoin, or gating)

three empirical findings - what are they and how are they explained in
(localist) connectionist models?
1. semantic interference vs. phonological facilitation
2. mixed errors
3. disruptions/disorders

understand how "classic" connectionist models of production diverge from other
connectionist work (localist, and fixed)
**** Ferreira and Slev - grammatical encoding

***** first read
Talk about "consensus model" where structure and content are planned
separately.  Then talk about debates: separation between selection and
retrieval; whehter content really is planned separately from structure.  Then
more debates: planning scope/incrementality, and syntactic choice.  Then (more)
"emerging" debates: priming, eye movements, storage/memory, disorders.

Close with "fundamental insights": linguistic and non-linguistic knowledge are
different (at some level); "syntax is in there somewhere"

Overall a little light on data for first bit but teh rest is really good.

***** debates
is there really strict separation between *structure* and *content* processing?
"consensus model" says yes...but alternative proposals say no?  Like lexicalized
tree-adjoining grammars, "combinatorial nodes" from pickering

"lexicalized accounts require additional processing machinery to explain
lexically-independent structure-building effects, most especially evidence that
syntactic persistence occurs completely independently of lexical content" -
similar trade-off as with exemplar models: makes some things easier to explain,
but others harder.

**** Meyer and Belke - word form/phonological encoding
Basic distinction: *selection* of lexical unit to produce, *retrieval* of word
form.  why?
- patterns of speech errors: whole word (cross phrases, same syntactic category)
  vs. phonological (same phrase, adjacent/close, different categories).  wider
  planning span at lexical/phonological level than phonetic level
- "tip of the tongue" states (some information about word but can't retrieve
  form); lexical representation has multiple components that have to be
  retrieved by different processes; corroborate by neurlogical case studies
- time course of lexical access: semantic/syntactic is available slightly before
  phonetic. 

serial staged vs. cascaded models (evidence favors cascaded, maybe with
feedback).

but all models agree: separate processes of selection of lemma and retrieval of
form.  this chapter focuses on *word form retrieval*.

rest of the paper: three phases of wordform retrieval: 
1. morphological encoding
2. phonological encoding
3. phonetic encoding

priming studies suggest independent *morphological representations* (with some
questions about derived forms, like ir/regular past tense)

speech errors (and re-syllabification/assimilation/etc.) suggest *phonological
representations* of words too.

things that are not independently planned: very few errors involve /single
phonological features/, but subsitutions/swaps share more features than expected
by chance.  Very few errors of whole syllables moving

interactive (feedback-y) vs. non-interactive models of morpheme-to-phonological
spread...challenge is neighborhood effects: dense neighborhood words easier to
produce.  easy to explain via feedback, harder without (has to go through
*comprehension system* via some monitoring system)

phonetic encoding: go from abstract phonological units to articulatory
gestures.  not a lot of models for this...one is the Levelt and Wheeldon "mental
syllabary"

***** Learning objectives
What's the basic source of evidence for understanding the structure of the
production system?  (speech errors, priming)

connect data on the role that segments play in planning/production with the
abstractionist/exemplar debates in comprehension.

Think about interactive vs. non-interactive theories...how do you explain
"feedback-y" effects (e.g. neighborhood density facilitation) without actually
having feedback?  (monitoring system, comprehension representations)

*** Questions
Each of these papers presents a "consensus model"...what's the relationship
between them?  Where do they agree, and where to do they conflict?  (Ryne
response...)

Relationship between production and perception mechanisms...

*** Learning objectives
Understand the structure/content distinction

Selection/retrieval (access?) distinction

Incremental/staged vs. cascading

Priming/persistence phenomena: What is the phenomenon? Why do they pose a
challenge to the models of production discussed in these readings?  How would
you account for them?



*** Plan for class
God, I dunno.  What actually matters here?
- speech errors as data source
- structure/content
- selection/activation
- priming

**** Prompt 1 - sources of evidence
What are the primary types of behavior/experimental designs that serve as
evidence for understanding production?

**** Prompt 2 - "consensus models"
Each of the chapters we read reviews a "consensus model" of production
('grammatical' encoding, word form encoding, and a generic connectionist
framework).  What are the points where these models agree?  Are there any
disagreements between the different "consensus" models?

(my answers: agree on some degree of separation between selection and
retrieval/access, and separation of different kinds of structural/content
information

** Clsss 6 - discours/pragmatics

*** Questions
Connect with last week...what do these pragmatic/discourse effects suggest about
the architecture of the "message planning" phase of production?

What do you choose to talk about and how?  And does that process have anything
to do with how you COMPREHEND things?

*** Readings

**** Brown-Schmidt and Heller - common ground/perspective taking
Common ground - information available to all and mutually acknowledged as such.

Taken for granted that adults represent perspective of others - questions are
*how* and *when* does that information influence language processing, and
whether it's shared between *comprehension* and *production*.

Contrast with *theory of mind* in psychology and *egocentrism* in social psych
and decision making (egocentric-first theories influenced perspective taking)

***** past
Clark and Marshal etc.: "diary of references" specific to particular partners.
Resolving references relies on /assumptions/ and /evidence/ via heuristics to
estimate common ground (requires infinite recursion otherwise)

Shorter referrential forms for common ground...longer when not in common ground.

Common ground is *actively constructed* by both speaker and listener
(grounding/backchanneling).

late 90s: real-time/on-line comprehension. (Keysar, Barr, et al. 1998): early
unrestricted search (common+priv ground), followed by restricted search.
Motivated partly by Tversky, but also by Fodor (common ground too hard to
integrate in real time).

but...constraint-based lexicalist approaches...including perspective of speaker
(cubby hole expt, with big/large objects in priv/common ground...)

production: under time pressure, speakers include unnecessary adjective ~half
the time (vs. 75% when both large/small available).  so...less than baseline but
still more than 0...so is it evidence for/against egocentrism?  it's
complicated: speakers often *expected to* draw on privileged ground "to make
felicitous contributions to the conversation"

***** present
focus shifted from /whether/ to /when and how/ perspective information is used.

"era of cataloguing":

Topics:
- sitauted conversation
- partner characteristics (stereotype, deficits
- partner's goals and beliefs - false beliefs, actions partner can make, desire
  to keep secrets

cognitive differences - memory/cognitive control.  but also experience.

demise of egocentric-first framework left fiedl *looking for a new framework*.

Interactive alignment (get perspective taking "for free" from more general
mechanisms), can explain things like conceptual pacts EXCEPT for the fact that
they CHANGE over time.

"Ordinary memory processes" - memory traces link partner and "contents of shared
experience", addressee serves as recall cue for previous referring expressions.
Central prediction: perspective-taking is *linked to shared experience*.  But -
not all perspective taking is through (direct) shared experience (Clark NYC
postcard task: speakers infer and adapt to addressee's level of knoweldge)

"seems unlikely" that domain-general cognitive processes can explain all
common-ground related phenomena...

***** future
previous attempts to explain perspective taking: it doesn't happen (Keysar), or
it's a byproduct of other domain general processes (alignment, memory)

computational models: bayesian pragmatics.  probabilistic which is good, adn
captures connection between comprehension and production (past comprehension
guides inferences about knoweldge state).  but...not cognitive models.

focus on referring expressions: "normally encode shared information" leads to
focus on /common ground/, rather than /privileged/ information.  need to broaden
the phenomena being studied to get a full understanding

questions - who do you ask, why, and how?  (declarative qs, contrastive
accenting)

type of knowledge mismatch - level 1 TOM (missing knowledge) vs. level 2 TOM
(different knoweldge/false belief)
*** Degen and Tanenhaus - scalar implicature
central question of pragmatics: "how context contributes to meaning"

strategic (smart, slow) vs. automatic (fast, dumb) processing...or,
unconstrained/conflicting inference vs. constrained inference

contrast "information privilege" accounts with constraint-based accounts of
scalar implicature
**** constraint-based approaches to language
four properties:
1. rapidly integrate  multiple weighted probabilsitic cues
2. generate expectations of multiple types about the future
3. rapidly adjust to differnet speakers/situation
4. architectural constraints are a last resort

ex: syntactic ambiguity

need to *identify and quantify relevant constraints*.

central role of context

linking hypotheses

richness of the signal
**** scalar implicature, "the drosophilia of experimental pragmatics"
"some-but-not-all".
**** approaches to pragmatics
two extremes: information privilege vs. parallelism

"literal first" and "Default" (conventionalized) hypotheses for scalar
implicature (opposite bias but same extreme hypothesis about time course)
**** constraints
"factors" whose settings vary across experiments (either explicitly or via
uncontrolled stimuli/settings) and which affect pragmatic processing

- QUD - "states of the world worth distinguishing for interlocutors" (can be
  different between two interlocutors!)
- world knowledge ("city council/protesters feared/advocated violence")
- cost/informativeness of utterance vs. alternatives: freq, length, complexity,
  social cost, etc.
- properties of speaker
- common ground
**** constraint-based approach 
early results: "costly implicature" incur processing delay (responding to "some
elephants are mammals" with pragmatic "FALSE" is slower than literal
"TRUE")...motviated *literal first* theories.

but...there exist contexts where scalar implicatures do not incur a processing
cost (VW eye tracking): if only "some" and "all" available, okay, but if "two",
"three", etc. also avaiable, costly

sometimes fast, sometimes slow - depends on context

constraint-based accounts are useful because they claim that probability and
speed of computing implicatures depends on contextual support.  so you can
measure the influence of different kinds of cues and make predictions about
un-observed combinations of them.  Combine corpus studies of support for scalar
implicatures of varying strength, and laboratory studies to investigate
individual factors carefully

resource constraints: less likely to respond pragmatically under load.
(explained by cue conflict?)

*** Learning objectives

Phenomena/concepts: Common ground, perspective taking/egocentrism, and scalar
implicature

Tasks/evidence
- "referrential communication task", privileged/common ground manipulated in
  various ways (e.g. cubby hole task).  Analyze *forms produced* and *real-time
  interpretation* (what would egocentric predict?).
- scalar implicatures - (speeded) interpretation/truth value judgement.

Role of theoretical traditions from other fields in shaping understanding and
study of perspective taking: egocentrism, modularity.

Draw parallel between modular/informationally privileged accounts here and in
syntactic processing and in phonetic/lexical access.

Think about the various notions of /context/ that are being invoked here:
linguistic context, discourse context, social context (informativity,
cooperative speaker) - role of context in constraint-based explanations of
processing difficulty.

*** Questions
How do we square evidence for resource limitations with constraint-satisfaction
theories?  (cue conflict I guess...you'd predict more sensitivity to resource
limitations when there are conflicting cues of roughly equal strength

What overlap, if any, is there between the phenomena that the readings from last
week (production) are trying to explain, and the phenomena from this week's
readings (discourse/pragmatics)?  (my answer: choice of what to produce?
real-time/online processing, time pressure?  modularity and interaction (not
phenomena really...)?  priming/adaptation/learning)

*** Plan for class
Going to (briefly) discuss BOTH sets of readings.

**** Prompt 1 -
Think back to the readings from last week.  What are the central
methods/experimental paradigms they're drawing on to understand production
processes?

(priming/interference speeded production tasks, speech errors)

What's the evidence from these paradigms in favor of a CASCADING model
(vs. STAGED/INCREMETNAL)?

- mixed errors: wouldn't be MORE likely to make mixed errors than the combined
  error rate if you FIRST select the word, THEN retrieve its form.

What's the evidence for separate stages for lexical SELECTION vs. RETRIEVAL?

- phonological facilitation and semantic interference

**** Prompt 2 - priming/persistence
What is the phenomenon of priming/persistence, and why is it a challenge for the
models of production from the readings to deal with?

**** Prompt 3 - 
What are the tasks/experimental paradigms used to investigate

(a) perspective-taking

- reference game/cubby-hole. - reference choice, speed, and eye movements

(b) scalar implicature?

- ...judgements about the implicature?  speed and 'accuracy'

**** Prompt 4 -
What are the /informationally encapsulated/ theories discussed this week?  What
do these predict in the experimental paradigms you discussed above for:

(a) perspective taking - egocentric(first): over-informative use in cubbyhole
game.  but LESS than in control situations (50% vs. 75%).

(b) scalar implicature - literal-first, Default hypothesis - predict 


(egocentric-first, literal-first, conventinalized)  

**** Prompt 5 
What overlap, if any, is there between the phenomena that the readings from last
week (production) are trying to explain, and the phenomena from this week's
readings (discourse/pragmatics)?

** Class 7 - sociolinguistics

*** Readings

**** Eckert - three waves
this is about "social meaning".  what's the relationship between social meaning
and language variation? 

***** First wave - survey methods/uniformitarian
"Filling cells defined by macrosociological categories"

class stratification, vernacular vs. standard language, language change

within-speaker variation is "self-monitoring to supress a natural cognitive
process" rather than "choice between socially meaningful forms"

link social variation (age-graded) with historical patterns of change
("assumption that the adult’s linguistic system reflects the state of the
language at some critical period in acquisition")

overall picture is: personal vernacular is "first acquired and most natural",
and people self-correct/monitor deviations from "standard".  Standard is
conservtive and resists change, so language change comes in via the
vernaculars.

BUT - leaders in change are not very lowest class/most vernacular...it's upper
working and lower-middle class with most "local engagement" - "suggesting that
vernacular variants are not simply the most natural way of speaking but have
some kind of positive indexical value related to locally based life"
***** Second wave - ethnography
seek out "local categories" which "shed light on the relevance of
macrosociological categories for life in the local setting"

jocks and burnouts: patterns not set in childhood but part of identity formation
in adolescence.

semiotic process of construction of polar oppositions from continuous
variation - recursivity (jocks/burnouts /within/ school communities embed the
urban/suburban class distinctions of the area), iconicity (whole constellation
of social practices including language take on iconic meaning associated with
the social groups), and erasure of gradual differences

***** Third wave - stylistic
Ethnographic and sociological perspectives focus on /static/ categories, and
"equate identity with category affiliation".

"beyond the regional and obviously nonstandard variables that have been the
bread and butter of the first two waves."

"indexical order": distinctive features of a group take on their own indexical
/meaning/ that can then be used in various moves.

"bricolage": reassembling borrowed components to construct new social meaning.
registers are input and output of this process..."enregisterment"

Beijing mandarin among international finance types (vs. local state-run
financial managers) - borrow variables from Taiwan/Hong Kong Mandarin, and
eschew variables indexed to particularly Beijing qualities/personas to project
cosmopolitan image

Pittsburghese: polish working class variables come to be associated with the
city as a whole /by people who have left or come from elsewhere/...need to be
taken out of context to be given broader meaning.

Variables can take on many different meanings in many different contexts
(asporation of intervocalic /t/ for instance: "indexical value associated with
hyperarticulation [... from] enregistered sources as divergent as British
English, Yiddish, and schoolteacher talk."

**** Loudermilk - psycholinguistic approaches to sociolinguistics
"computational stages and cognitive representations underlying the perception
and production of sociolinguistic meaning".

***** How dialect variation is represented, perceived, and learned
Forced choice/free classification of american dialects - pretty bad but
experience matters - sensitivity to broad patterns but also maybe more
fine-grained?  e.g. free classification of 6 dialects into on average 10 groups,
but only three major groupings (NE, S, midwest/west) consistent.

repetition priming - final /t/ variants (full, partially glottalized, glottal) -
all variants immediately prime (lexical access), but only full [t]-[t] pairs see
long-range repetition priming.  similar pattern for "r-full" vs. "r-less" NYC
dialects - r-less NYC speakers show semantic and both short- and long-term
repetition priming (although weaker for r-full prime/r-less target and
vice-versa than for matching), while r-full (2nd gen) NYC speakers don't show
long-term priming after r-less primes (but do show short-term), and GA listeners
only show priming after GA primes

Clopper & Pisoni (2004a): one-talker vs. three-talker dialect ID
training...better learning of talker ID and sentence comprehension after
1-talker training but better generalization to new talkers after three-talker
training.

Syntactic priming of unusual number agreement patterns (happens, and varies by
age/gender/etc. of speaker)
***** Stereotypes in speech processing
Niedzielski (1999) - don't perceive canadian raising when think talker is from
detroit

Hay et al. (2006) - NZ/Aus /ɪ/ (raised in Aus, centralized in NZ) biased by
toy/label on sheet

Staum Casasanto (2008) - mass/mast (coronal deletion) + race: faster to respond
to plausible continuation consistent with race of face

Strand and Johnson (1996) - gender stereotypes about s/ʃ

***** Attitudinal aspects
Matched-guise - hold speaker constant, vary "guise" (langauge, dialect, etc.)
and make ratings (intelligence, friendliness, etc.)

Labov et al. 2011: newscaster professionalism vs. frequency of [ɪn-ɪŋ] /-ING/
variants.  ratings depend on location and gender of rater and freq of variant

Campbell-Kibler (2006,2007) - excerpts from natural conversations instead of
script, re-recorded with [ɪn] and [ɪŋ] variants.  complex effects on ratings
(southernness, gay, class/education).  "single variant can realize multiple
social meanings"

IAT - implicit measure vs. explicit from the matched guise task.  largely agrees
with production and matched-guise data for /-ING/ variants, but sometimes
diverges (foreign vs. standard US accents).

***** Eye tracking and ERP studies
bag-back minimal pair and /æ/-raising before /g/: fewer errors on "back" after
exposure to raised-/æ/ dialect, and fewer competitor fixations 600ms after vowel
offset.

pin-pen "unmerger" in southern cities (Houston), age-graded.

ERP: formal/informal -ING, congruent or non-congruent with context, high/low
cloze probability.  Independent N400-like effects of close probability and
variant, but consistent negativity for informal, regardless of context?

*** Questions
Social variation - on a continuum, or discrete categories?  Is it different in
the world vs. in the mind? (e.g., the Preston study with Indiana/Michegan
listeners making north/south boundaries differently) - also related to the
discussion of jocks and burnouts ("continuous sociolinguistic geography" of
suburban detroit vs. "construction of the polar opposition" between jocks and
burnouts).

What paradigms are we seeing here?  (priming, speeded judgements, forced-choice
classification)

Does knowledge of socially-indexed language variation reflect some kind of
veridical statistical knowledge of those patterns, or not?  Why or why not?

How, as psycholinguists, can we meaningfully study the role of language in
communicating and constructing /social/ meaning?  Is that anathema to the normal
practices and standards of the psychological science of language processing?
(To me, this is really tricky:  social meaning is so idiosyncratic and
context-dependent that it seems really hard to study it in any kind of
controlled way in the lab...which is not to say that it's an intellectually
worthwhile thing to study, just that it's hard to integrate it into our
communities of practice...)  related: matched guise/IAT experiments

Link between last week (pragmatics, what you COULD have said affecting the
meaning of what you did) and indexical fields ([ɪn] by Northerners is read as an
affectation of folksiness, [ɪŋ] by Southerners as pretentious).

What does "iconic" mean in the context of third-wave sociolinguistics?

Why do some linguistic variables come to be "indexical" while others don't?
(Yarkin's question)  And where do the "trait" associations come from?  (Related
to psycholx/sociolx disconnect...)

What role does explicit indexicality/pose play, vs. just immitation/accomodation?

*** Learning objectives

Identify the "three waves" of sociolinguistic study and the major
differences/developments that mark the transitions.

Identify the major behavioral paradigms and data sources used in the study of
language variation and how people produce and process it. (Survey/corpus
studies, matched guise, priming, forced choice/free
categorization/identification).

Think about the challenges of incorporating social meaning into psycholingustic
studies, and how social meaning in the different waves is incorporated into
psycholinguistic methods and theories.

Draw parallels with pragmatic inference?

Think about whether social and linguistic variation are /continuous/ or
/categorical/, and how you'd tell.  Is the answer to this question different
when we consider /variation in the world/ and the /mental models of that
variation/ that people have?

*** Plan for class

**** Prompt 1 - the waves
Identify the "three waves" of sociolinguistic study that Eckert describes, and
the major differences/developments that mark the transitions.  What kind of
social meaning is the focus of each wave, and what kind of linguistic variation?

**** Prompt 2 - empirical evidence
What are the major sources of empirical evidence (e.g. /experimental paradigms/)
about the nature of language variation and how it's processed/represented by
listeners and speakers?

matching, priming, explicit judgement

**** Prompt 3 - socio-psycholinguistics
Does psycholinguistics /need/ to consider social meaning at all, or is social
meaning independent enough of "general" language processing that the two can be
considered on their own?

On the one hand, no, I don't think we NEED to consider social meaning, at least
not all the time...it's possible to study language processing without directly
investigating social meaning per se, just like it's possible to study, say,
phonological processing without considering semantics...it might not get you ALL
the way there but you can certainly learn things that way.  On the other hand,
I think social meaning constitutes a really important source of context and
structure that provides additional constaints/structure for language
processing...so from the perspective that context/constraints really matter,
then it seems hard to avoid, but not more or less hard to avoid than any other
kind of context.

What are the major /challenges/ for incorporating social meaning into the
psycholinguistic study of language and language processing?  These could be
conceptual or methodological challenges.

...but that brings me to the challenges, which is that as a source of additional
constraint/context it's SO much more slippery and contextual than the other
things we've looked at, which are relatively stable (syllabic structure, syntax,
etc.), with the possible exception of pragmatics, but even there you can get at
it with joint tasks and constrained discourse structure, privileged/common
ground, etc.  But social meaning feels...different, harder somehow.  It seems
hard to really deal with it seriously without reaching outside the bounds of the
laboratory...

**** Prompt 4 - continuous vs. categorical
Is social meaning and the language variation that indexes it /continuous/ and
graded, or /categorical/ and symbolic/discrete?  Why?  It might help to consider
separately (1) the variation that actually /exists in the world/ and (2) the
mental model or representations that speakers and listeners use in producing and
comprehending social meaning.

** Class 8 - learning/adaptation
Assigned two of the "classic" recalibration papers, with optional readings for
syntactic and pragmatic.

*** Readings
part of what's interesting to me here is reading these papers from our vantage
point now and trying to project back to how these would have seemed in the
context.

**** Norris et al. 2003
Experiment 1 - /s/ and /f/ final words, replaced one set with ambiguous
fricative.  Shift in classification of /ɛf/-/ɛs/ continuum after exposure.

Experiment 2 - rule out selective adaptation or contrast effects.  Add two new
conditions - natural only (ambiguous words replaced with fillers) and
ambiguous-nonword (leaving only natural endpoint).

Interesting to me that in both experiments there's a fair amount of variability
between people and words/frames in the willingness to accept the lexical cues
(especially with potential coarticulatory cues that come from using a /f/-final
frame).
**** Bertelson et al. 2003
Experiment 1 - just ambiguous mcgurk stimuli, blocks of 8 exposure/6 test,
random order of 8 repetitions of each.

Experiment 2 - add prototypical too in order to ... I forget what.

They frame all this in terms of whether there are recalibration aftereffects in
speech...previous work argued no, but that was all with high-conflict mcgurk
stimuli (ba-va or ba-ga)
*** Questions
How do we know that people in these experiments are actually using the
information source the authors claim (lexical or visual/articulatory info)?

How can we explain these results?  How would you explain them in the context of
- an IAC type model like TRACE
- an exemplar model

What do these results tell us about modularity of speech perception?

Do we need to appeal to re-mapping the way the low-level sounds themselves are
processed?

**** From response papers
Lots of questions about how the stimuli are constructed and what the effect of
naturalness is...I think that's really interesting too.

Does it matter that the continuum might not reflect natural patterns of
within/between talker variability?

Also lots of interest in the cognitive penetrability stuff.

And confusion about the online/offline feedback stuff from Norris.

*** Learning objectives
identify the sources of "self-supervision" signals here.

prototypical vs. ambiguous adaptors.

identify what the implications of perceptual learning/recalibration are for
theories of speech perception.  what kinds of models are compatible with these
phenomena?  Can you translate the learning mechanisms discussed in Norris et
al. paper to the Bertelson?

compare and contrast ideas about the role of top-down context/information we've
encountered elsewhere with the role that context is playing in
recalibration/perceptual learning/adaptation. - what's the role of top-down
information/context in other areas, and is it playing a different kind of role
here or basically the same kind of role?

supervised vs. unsupervised learning - is the perceptual learning we're looking
at here /supervised/ or /unsupervised/?

draw parallels between the necessity of using ambiguous stimuli to elicit
recalibration / learning and the necessity of using balanced stimuli / avoiding
/conflicts/ between strong cues in the constraint-based accounts of parsing.

*** Prompts for discussion

**** Prompt 1 - methods
How are the ambiguous stimuli constructed in these two experiments?  How is
learning measured?

**** Prompt 2 - supervised/unsupervised learning
The phenomena in these papers can be viewed as a form of /perceptual category
learning/.  Is this learning better thought of as /supervised learning/ (where
there is some kind of external information about the category), or /unsupervised
learning/ (where it's up to the subject to figure out the categories)?  Is your
answer the same for the two papers?

My thoughts: usually the supervision signal is coming from /outside/ the system
right?  Like you're being told by the experimenter that this is an A or a
B...but in both these cases the signal is maybe coming from internally, which
makes it feel more unsupervised.  On the other hand...there clearly IS a
teaching signal here, even if it's internally generated...in the case of
Bertelson it's the link between the visual/articulatory information and the
possible phonemes (but even then it's not totally unambiguous!), and in the
Norris case it's lexical.  Still both of these rely on internal assumptions to
provide a useful teaching signal!  The articulation is not enough to tell you
that it's /aba/, just that there's some labial involvement, which combined with
something that's halfway between /b/ and /d/ is enough to resolve the ambiguity.
And for the lexical stuff, you ARE HEARING many non-words, so the other category
interpretation is not out of the question!  I wonder whether including more
non-words that are one phoneme off from a word would reduce the strenght of the
adaptation effect.

Joselyn and Yarkin and Joseph - lexical is MORE clear

**** Prompt 3 - role of top-down information/context
Compare and contrast ideas about the role of top-down context/information we've
encountered elsewhere with the role that context is playing in
recalibration/perceptual learning/adaptation.  What's the role of top-down
information/context in other areas (speech, lexical access, syntax/parsing,
pragmatics, etc.), and is it playing a different kind of role here or basically
the same kind of role?

** Class 9 - talker specificity

*** readings
Kamide - high/low attachment preferences

Ryskin et al. (2020) - atypical catgory exemplars + cover stories, ERP

Kraljic et al. - generalization or not

Nygaard and Pisoni (1998) - familiarize to 10 talkers, test on
familiar/unfamiliar speech in noise ID.  isolated words or sentences (no
evidence of cross-genearlization though...)

Bradlow and Bent (2008)

I think we're gonna do is the B&B, and Kraljic & Samuel 2006 and Eisner et
al. (2005) (the Kraljic 2005 is ... a lot).

Bradlow, A. R., & Bent, T. (2008). Perceptual adaptation to non-native
speech. Cognition, 106(2),
707–729. https://doi.org/10.1016/j.cognition.2007.04.005

Eisner, F., & McQueen, J. M. (2005). The specificity of perceptual learning in
speech processing. Perception & Psychophysics, 67(2), 224–238.

Kraljic, T., & Samuel, A. G. (2006). Generalization in perceptual learning for
speech. Psychonomic Bulletin & Review, 13(2), 262–268.

**** Optional
Kamide, Y. (2012). Learning individual talkers’ structural
preferences. Cognition, 124(1),
66–71. https://doi.org/10.1016/j.cognition.2012.03.001

Yildirim, I., Degen, J., Tanenhaus, M. K., & Jaeger,
T. F. (2016). Talker-specificity and adaptation in quantifier
interpretation. Journal of Memory and Language, 87,
128–143. https://doi.org/10.1016/j.jml.2015.08.003

**** Eisner and McQueen 2005
Experiment 1 - replicate Norris et al. with different talker, plus two new
groups where test continuum was exposure talker's fricative continuum on new
talker's vowel (both female) - still see PR

Experiment 2 - male talker + exposure fricatives, still see PR (!)

Experiment 3 - male talker's fricatives at test, no PR (or much weaker)

Experiment 4 - male talker's fricatives in EXPOSURE with female talker's carrier
words, male post-test - strong PR.

**** Bradlow and Bent 2008
Frame this in context of perceptual learning, structured variation, some
evidence of generalization, use of top-down/lexical knowledge to guide learning.

Experiment 1 - single talker presentation of low/med/high intelligibility
Chinese accented talkers + med intel. slovakian.  overall find improvement over
quartiles, better comprehension for single- vs. multi-talker condition.

Experiment 2 - single- vs. multi-talker expsoure + a post-test with chinese or
slovakian talker.  single talker is either same as post-test or different.  
*** Questions
Big one is...when does experience with one talker affect processing of another?
Is perceptual learning/recalibration talker-specific, or generalize?  If we have
long-lasting memories for individual talkers that makes it easier to understand
them in the future, how is it possible that we can also generalize?

What is a "talker" here?  A voice?  A single person.  That is, at what level is
the match/mismatch calculated?

Where does this leave exemplar models? - on the one hand, low level SOUND match
seems to be what's being learned (fricatives cross-spliced from one talker to
other).  on the other, you get generalization in quite different vowel frames,
talkers, etc.

Differences in how stimuli are generated for the two studies: waveform averaging
vs. multi-cue continua

What do these studies conclude about what is learned in perceptual learning?
What is the /linguistic locus/ of learning (feature, segment, phoneme, word,
larger?)  What is the /indexical locus/ of learning (talker? group of people?
something else?)

*** Prompts

**** Prompt
What does each of the three readings conclude about what is learned during
perceptual learning?  What is the /linguistic unit/ that is the locus of
learning, and what is the /social/indexical/contextual unit/ that each paper
appeals to?  What is the basis for these claims in each paper?

***** my thoughts
Eisner & McQueen - it's the phoneme/segment (the actual fricative itself).  not
totally clear what the indexical unit is...maybe talker?  Maybe something more
fine-grained like the actual acoustics of the segment?  You get generalization
as long as the fricative itself mathces which makes me think it's not JUST
talker...

Kraljic & Samuel - they come down on something like a feature...voicing, since
it generalizes to other phonemes (dt-bp).  for the indexical, they're not so
clear...something broader than talker, certainly.  but it's hard to say whether
they expect things to genearlize outside the experiment

Bradlow & Bent - they're "blaming" learning on correlated constellations of
features that span multiple phonemes/words, but they don't realy have a way of
clearly distinguishing that from a collection of individual shifts/deviations
OTHER THAN the finding that learning generalizes when you have a bunch of
similar talkers (same native language background).

**** Prompt
What are the differences in materials/procedure that might be relevant for
understanding the divegent findings in Kralijc & Samuels vs. Eisner and McQueen?
What about Bradlow and Bent compared with the other two?  Are these differences
enough to explain the divergent findings?

- fricatievs have more talker cues in them?
- more cues were manipulated in teh continuum for d-t so maybe it's more
  shifting a boundary on an existing space vs. mapping onto a new space

**** Prompt - theories
Where does this leave the major theories we've discussed so far?  Consider at
least TRACE/IAC-style localist connectionist theories and episodic/exemplar
theories.  What aspects of the findings from this week (and last week) do they
explain naturally?  What things do they struggle to explain?

Keep in mind when you're thinking about this that none of these theories were
exactly /designed/ to handle this data, because it didn't really exist when the
theories were being developed.  That's what makes it interesting to try to fit
the findings into an existing framework.  One way to think about it is, what
about these findings would /surprise/ you if you were a real believer in
TRACE/IAC models, or exemplar models?  And what direction do these findings
force the various theories to move in terms of the kind and size of
representational units, the role of top-down information, etc.?


** Class 10 - Bayesian models

** Class 11 - Information theory

** (No class, thanksgiving)

** Class 12 - Noisy channel

*** Possible readings
Gibson, Bergen, and Piantadosi (2013; PNAS) - evidence for semantic/syntactic
integration via noise model

Ryskin et al. (2018) - model nature of noise



