#+TITLE: Grad psycholinguistics
#+STARTUP: indent children

* Scheduling

whenisgood: t748bj http://whenisgood.net/ywa7dkt/results/t748bj2
http://whenisgood.net/ywa7dkt

* structure
a few weeks on "foundational" stuff: speech perception, sentence processing,
production?, pragmatics

** organizational meeting
  
** what is language and why psycholx
  
** speech perception
categorical perception/continuous perception

might also require introduction to the speech signal itself (for non-ling
folks).

** spoken word recognition
   
   
** Sentence processing
garden path sentences, ambiguity, parsing

DLT?  classical parsing (content free) vs. lexical/constraint satisfaction
models (MacDonald stuff?)
   
** production
speech errors, sentence production too?

** pragmatics/discourse
RSA vs. traditional models?  or even more basic...

** sociolx
"three waves" of sociolx; 

** Info theory
syntax: levy/smith and levy

word structure (piantadosi stuff)

** noisy channel models
how/why are these distinct from purely "bayesian"/ideal observer models?
thinking about the production stuff and the Ryskin paper on learning the
noise model...

** learning and adaptation
lots of stuff here...

** speaker specific representations
I'm thinking both the long-term memory stuff in speech and the Kamide work on
high/low attachment preferences, maybe also informativity

** structured vs. structure free
examplar models vs abstractionist

** variation and structure (and maybe sociolx?)
what kind of structure is there?  (chodroff, tanner, my LCN paper)

* Preliminary schedule
** 2020-09-01 Organizational meeting
** 2020-09-10 What and why
** 2020-09-17 Speech perception
** 2020-09-24 Spoken word recognition 
** 2020-10-01 Sentence processing 
** 2020-10-08 Production 
** 2020-10-15 Pragmatics/discourse 
** 2020-10-22 Sociolx 
** 2020-10-29 Learning and adaptation 
** 2020-11-05 Talker specificity 
** 2020-11-12 Bayesian theories 
** 2020-11-19 Information theory 
** 2020-11-27 NO CLASS (thanksgiving)
** 2020-12-01 Noisy channel models 
** 2020-12-08 (Final presentations)
* topics/theme
I think the overall theme is going to be variability vs. structure.  How much
do these affect processing?  How are they each represented?  What are the
computational demands they each pose?

Then there are the "classic" debates in psycholx: parsing wars, interactive
activation vs. feedforward, prediction.

The other big question is how foundational vs. "what I'm interested in now" to
make this.  More and more I'm leaning towards foundational (it'll correct some
of the things that are missing in Sten and Joselyn's preparation and probably
be more useful/interesting for the others...).  But putting together a reading
list is a little harder there I guess, so...  Maybe the first few weeks are
going to be "basic stuff you need to know" and the last few weeks will be
special topics?  I dunno.

what's the point of this class?  what are these students going to get out of
it?  they're all graduate students.  not all of them are studying language,
but many of them are.
  
** continuous vs. discrete  
e.g. categorical perception, graded grammaticality

** top-down vs. bottom-up processing
** exemplar models

** availability vs. info theory models (production) 

** stability vs. plasticity

** parsing wars: structure or content?
** methods
eye tracking, corpus, psychophysics, self-paced reading, computational
modeling

especially interesting angle might be behavioral methods...how is language
processing reflected in BEHAVIOR?  what are the relevant behviors and what do
we know about them?  What kind of information can we hope to get from
language-related behavior?  What's the time/spatial/social scale at which
we're studying this behavior?
   
** acquisition (related to stability/plasticity?)

** what information is used when 
modularity vs. interaction.  perspective taking.  socio stuff.  prediction
vs. integration.

** role of context
   
** is speech/language special?
to what extent can speech processing be explained by general auditory
mechanisms?

* other classes
  
** BCS 501 (chigusa and mike version 2017)
[[https://docs.google.com/spreadsheets/d/1rQjU2_a6jeoXle8hGFT93jem8XidXOs6dUcungDXz-A/edit#gid=1386834576][Schedule and readings]] [[https://docs.google.com/spreadsheets/d/1WaMJ0N-7XvIcpCCY56_dwVd-XRVJD4nhOsgHngh4nic/][(my copy)]]

They spent first 8 classes on foundational stuff...lots of reading from the
oxford handbook plus some supplemental stuff.  Then 6 classes on more current
stuff I guess.

It's a very "mike and chigusa" flavored set of topics...lots of spoken word
recognition, information structure

I guess I don't necessarily need to cover exactly the same material since the
language people are all in my/karin's lab.  but I think some depth is going
to be really important.
** BCS 501 (chigusa and mike 2015 version)
2x weekly, much more of a survey.

** BCS 501 (Mike's lang class)
This was pretty basic or introductory from what I remember...or rather,
foundational.  There was a lot of reading.  No syllabus but I have the emails
with readings/topics 

*** week 1
Chomsky, N. (l980). Rules and representations.  The Behavioral and Brain
Sciences, 3(1), 1-15.

Miller, G.A. ( l965). Some preliminaries to psycholinguistics.  American
Psychologist, 20(1), 15-20.

Miller, G.A. (l990). The place of language in a scientific psychology. In G.A.

Miller (Ed.), Psychological Science, 1(1), 7-14.

Seidenberg, M. (1997) Language acquisition and use: Learning and applying
probabilistic constraints.  Science, 275, 1599-1603.

Hauser, M. D., Chomsky, N., &amp; Fitch, W. T. (2002). The faculty of language:
What is it, who has it, and how did it evolve? Science, 298, 1569-1579.

*** week 2

*** week 3? dick aslin guest lecture
probably something about speech...I have the slides 

*** (missing week)
*** sentence processing

Frazier, L. (1987).  Sentence processing: A tutorial review.  In
M. Coltheart (Ed.), Attention and Performance.  Hillsdale, NJ: Lawrence
Erlbaum Associates.

Gibson, E. (2002).  Linguistic complexity in sentence processing.  In Oxford
Encyclopedia of Cognitive Science

Marslen-Wilson, W.  (1973).  Linguistic structure and speech shadowing at
very short latencies.  Nature, 244, 522-523.

Marslen-Wilson, W.  (1975).  Sentence perception as an interactive parallel
process.  Science, 189, 226-228.

Levy R. (2008) Expectation-based sentence processing.  Cognition
    
Tanenhaus, M.K. & Trueswell, J.C.  (1995). Sentence comprehension.  In:
J.L. Miller & P.D. Eimas (Eds.). Handbook of perception and cognition
Vol. 11: Speech, language and communication, 217-262.  San Diego, CA:
Academic Press.

*** sentence production
Griffin, Z. M. (2003). A reversed word length effect in coordinating the
preparation and articulation of words in speaking. Psychonomic Bulletin and
Review, 10(3), 603-609.

Ferreira, V. (1996).  Is it better to give than to donate? Syntactic
flexibility in language production.  Journal of Memory and Language, 35, 724-755
    
Dell et al. (2008) Saying the right thing at the right time


*** perspective taking?
Wardlow Lane et al. (2006) Don't Talk about Pink Elephants!

Keysar et al. 2000 Taking Perspective in Conversation
*** lissa (development)

Lenneberg, E.H.  (1969).  On explaining language: The development of
language in children can best be understood in the context of developmental
biology.  Science, 164, 635-643.

Gleitman, L.R., & Newport, E.L. (1995).  The invention of language by
children: Environmental and biological influences on the acquisition of
language.  In L.R. Gleitman and M. Liberman (Eds.), An Invitation to
Cognitive Science, 2nd ed.  Vol 1: Language.  Cambridge, MA: The MIT Press.

Newport, E.L.  (2002).  Critical periods in language development.  In
L. Nadel (Ed.), Encyclopedia of Cognitive Science.  London: Macmillan
Publishers Ltd./Nature Publishing Group.

Optional: Pinker, S. & Prince, A.  (1988). On language and connectionism:
Analysis of a parallel distributed processing model of language acquisition.
Cognition, 28, 73-193.]

Newport, E.L., & Aslin, R.N. (2000). Innately constrained learning: Blending
old and new approaches to language acquisition. In S. C. Howell, S. A. Fish,
and T. Keith-Lucas (eds.), Proceedings of the 24th Annual Boston University
Conference on Language Development.  Somerville, MA: Cascadilla Press.

Marcus, G., Vijayan, S., Bandi Rao, S., & Vishton,
P. M. (1999). Rule-learning in seven-month-old infants, Science, 283, 77-80.

Aslin, R.N. & Newport, E.L. (2011).  Statistical learning: From acquiring
specific items to forming general rules.  Current Directions in
Psychological Science, in press.
*** visual world
*** adaptation
(maybe this is from teh LSA institute?)
** Lang and Cog
could do like an advanced version of this?
** my own quals
psycholx section has some foundational stuff too...

* meetings 

** week 0 - organizational

*** Agenda
Scheduling

Syllabus

Work and grading

Final project

Topics

*** Tuesday 12:30
Meet next week?

** week 1 - what/why
   
*** Planning
    
**** Questions for discussion
Does the performance/competence distinction still matter?  What role did it
play in the historical development of psychology/cognitive science?

How important is communication in understanding language?  Is language
"for" communication, or something else?

Can language /behavior/ tell us anything about linguistic /knowledge/?
Conversely, is it possible to study language /without/ studying linguistic
behavior?

Why might language as Chomsky saw it be a challenge for behaviorism?

How does the idea of innate linguistic knowledge ("universal grammar") fit
with our current understanding?  What role does it play in current thinking
in the field of formal/Chomskian linguistics?  What about
psycholinguistics?

Many of these papers make a contrast (explicitly or implicitly) between
/statistical/ models and /grammatical/ models of linguistic knowledge.  Are
these really in opposition?  Why or why not?

Psychology and cognitive science have gone through a number of periods
where different conceptions of what a good theory reigned.  What's the
current paradigm in your area?  How is this period going to look in the
light of history?

**** Introductory topics

"Scruffies and neats": "Roger Schank actually notes that he originally made
this distinction in linguistics, related to Chomskian vs. non-Chomskian,
but discovered it works in AI too, and other areas. " [[https://en.wikipedia.org/wiki/Neats_and_scruffies][(wiki)]]

Marr's levels of analysis?

Language /structure/ vs. language /content/; grammar vs. statistics

pendulum swings: stastical/surface vs. structural/deep

Basics of linguistics: performance vs. competence

     
***** history
History of modern cognitive science/psychology; behaviorism and the
cognitive revolution; the advent of connectionism

evolution of the idea of /universal grammar/: from very specific
structural knowledge to...recursion

degree of interest in (different kinds of) behavior
      
***** themes
Draw your attention a a couple of high-level topics and themes that tie
these papers together.

1. What language is /for/: communication, representation, something else?
   (Related to the evolutionary origins of language and the nature of
   linguistic knowledge)
2. Linguistic /knowledge/ vs. linguistic /behavior/ (competence
   vs. performance)
3. The role of statistical/probabilistic information in language
   processing and in linguistic knowledge (is the grammar probabilistic?)

**** what's the plan
the idea for this week is to situate psycholinguistics in the broader
context of the field of psychology, and linguistics (and cognitive science,
more broadly).

So we read papers that try to give a concise overview of (some of) the
history of cognitive science and the role of language in that (Miller), and
some foundational issues in what we mean when we talk about language
(communication, Hockett; grammar, HCF; statistical knowledge, Seidenberg)

There's also this narrative that Chomsky is single-handedly responsible for
dismantling the dominant behaviorist paradigm in his review of Skinner's
/Verbal Behavior/; the Miller papers place that in a slightly broader
context as well, as one part of the cognitive revolution in psychology
which was well underway by the time Chomsky was writing that.

**** yea but what are we going to DO during class
discuss readings ... use them as jumping off point to talk about bigger
issues (see questions above)

**** order to topics

***** Miller (history)

***** Hockett; HCF; Seidenberg

** week 2 - speech
   
*** Readings
handbook chapters: Gaskell plus Pisoni & Levi.

**** Pisoni and Levi
Argue that encode BOTH abstractions AND details of specific instances

3 basic assumptions of "traditional approaches":

1. set of discrete and linear symbols to represent continuous speech
2. symbols are "abstract, static, invariant, and context-free"
3. psychological processes "normalize" acoustic differences

   Problems with the traditional view: non-linearity of the acoustic signal
   (coarticulation/smearing); lack of (acoustic-phonetic) invariance;
   segmentation is hard.  Many of these spring from a *bottom-up* approach to
   speech recognition (sounds → phonemes → words).

***** Evidence for specificity in speech encoding
Mullennix et al. (1989): intelligibility lower and repetition slower in
multi-talker lists

Mullenix & Pisoni (1990): attend to words slowed by voice variabiltiy, and
vice-versa (but easier to ignore word variability than voice)

Specific voice details encoded in recognition memory (even with lots of
talkers), up to a week

Speaking rate variation affects identification, but not amplitude.

Speaking rate variation also affect recall memory (primacy)

Nygaard et al. (1994): novel word recognition easier for familiar voices
than unfamiliar

Allen and Miller (2004): speaker-specific VOT dists, generalize to unheard
words.

***** 

**** Gaskell
Some confusion about the different models, that's understandable.
      

*** Questions for discussion
    
**** What makes a representation "abstract"? 
see Sten's response paper...also Huteng.  Is "abstract" vs. "episodic"
really the best way to think about the tradeoff here?

also Joselyn: talking about degree of abstractness in layers in TRACE.

**** What Marr level do exemplar/episodic theories target?

**** Tradeoff between number/granularity of representations and processing
Normalization/compensation for context is necessary to reach something like
an abstract, context-free symbolic representation.  Exemplar models avoid
this by just storing enough relevant context to make normalization
un-necessary, but this massively increases the amount of possible
representations in your system...

what's the benefit/cost of each approach?

**** why did it take so long?
most of the ref's in the Pisoni & Levi chapter about the problems for the
"traditional view" are from the *1950s*!!
 
**** exemplar models and "coupling between ... prior experiences" and current processing
     
**** what is the evidence for exemplars?

**** what is the evidence for abstractions?

**** what's noise and what's signal
from Joseph's paper: each extra source of variation makes local
interpretation more difficult, but maybe together they make GLOBAL
interpretation easier?
     
*** Material for context
    
**** categorical perception
     
**** "lack of invariance"
coarticulation and talker variabiltiy are two big ones
**** Different types of models

***** "Traditional" (abstractionist) models
have something like a "template" for each phoneme/allophone in your
language.  compare the speech stream to these templates to get
phonemes/allophones, then that is input into symbolic processing in the
phonological grammar.

***** IAC
TRACE as an example

***** distributed connectionist models
not really clear on these here...I guess this is the DCM, which uses an
SRN to take in phonetic features and output "a distributed representation
of lexical content"

***** statistical models
I think they're talking about like n-gram models here.

***** exemplar models
episodic version: store detailed, un-analyzed acoustic traces in memory
(think: raw spectrogram).  phonolgical representations emerge from
similarity-based retrieval.

**** relations between model families
"connectionist models" are a big tent: include "localist" models like
TRACE, "distributed" models like DCM

** Week 3 - lexical access
   
*** Readings

**** Marslen-Wilson 1989
Lexicon links *form* and *content*, two kinds of processing, "access" and
"integration"
     
Interpretation is continuous and immediate

What's the relationship between form and content based processing?  Early
selection in context (before form is enough) suggests that selections
guided by content too

This is *fast* so it has to be happening in parallel (both access and
"assessment", comparison to contextual constraints)

(cohort model: how is this different from e.g. TRACE?  one big one: no
mutual inhibition between active words)

/contingency of perceptual choice/ in the cohort model: "outcome and timing
of the selection process are determined by the properties of the /complete
ensemble/ of perceptual possibilities open to the listener".  (selection
happens when you have a winner, which depends on who else is playing)

"Cues to any individual phonetic segment are distributed over time, and, in
particular, they overlap with cues to adjacent segments" (p. 9)

gating task: 25ms gates...free response.  place of articulation AND final
stop voicing (vowel duration) both show continuous access.

directionality: initial mismatch rules out items?  compare cross-model
priming for cohort overlap (ambig, presented mid word, vs. end of word, when
it's not ambiguous), and rhyme overlap work/nonword (complete).  Find no
priming for rhyme overlap, despite similar amounts of overlapping material
as with onset (but I think TRACE et al. can still explain this?)

parallel activation of semantic content: cross-modal form based priming
([kapit] primes "boot" (boat) and "geld" (money))

what's the role of context?  pre-selection?  argues against this: effects
of context in a cross-modal priming task only show up once you reach the
uniqueness point of the prime word, even in highly-constraining contexts.

there's a puzzle here though: in an actual gating task with the same
stimuli, you can identify the final word much earlier than the point at
which cross-modal priming effects seem to kick in.  argues that priming is
basically a lexical effect, whereas the integration is happening..somewhere
else?  hard to say.
     
overall comes down on the side of lexical access being a *Fodorian input
system* (primacy of the bottom-up input).

**** McQueen 2007
     
     
**** Comparison
MW focuses mostly on the bottom-up information...primacy of the signal.

One point of contrast is that there's a lot more nuance in the McQueen
summary when it comes to *mismatch*: MW basically just says if there's a
mismatch then that's bad (does he?  does he also talk about sub-categorical
mismatch?)
     
Evidence that rhyme-overlap are also considered discussed in McQueen
(p. 42).

*** things from response papers
**** Ryne
what's the relation with these papers and the "traditional" level from
papers last week?  Seems like these authors are both taking the traditional
view...

recognition point vs. uniqueness point

**** Huteng
Doesn't cite any phonologists...

What is the cohort model, really?  What is the gating technique?

**** Yarkin
segmental vs. suprasegmental information...can they really be separated?

**** Joseph
relate these to predictive models like GPT and SRN...(to me, interesting
question is how much and what kind of context are involved in capturing the
predictions people seem to be making?)

*** Questions

If content/context influences form-based selection in lexical access, how
could the models we discussed last week account for that?  What kind of
predictions would that make?

Integration vs. prediction ("true" top-down vs. "only integration"
effects)...how can you tell them apart?  What are the readings suggesting
about that?

Let's look critically at the assertion from Marslen-Wilson that the
bottom-up signal has primacy in lexical access in light of the more recent
findings summarized by McQueen (coarticulation, assimilation, use of
phonological knowledge, context effects)

What about the claim of directionality?  What's the evidence for this?  Are
there alternative explanations for these findings?

Are any of these effects /incompatible/ with an exemplar model?  Are any of
them easier/more natural to explain with an exemplar model than a
"abstractionist" model where lexical access is mediated by sublexical
representations?  (Maybe the suprasegmental stuff, like the "'ham' in
'hamster'" effect...)

*** Learning goals for this week     
Identify the methodologies that are used to investigate lexical access in
these papers (cross-modal priming, gating, word identification)

Think about the relationship between the *cognitive processes and
representations* as distinct from the *methods* we use to probe them (e.g.,
word identification shows early use of context information, but cross-model
priming does not).
    
Be able to explain how we know that word forms and meanings are activated in
/parallel/ during lexical access.

Think about the role of top-down processing in lexical access.  Does it play
any role?  What is the role?  What sort of information is involved in
top-down lexical access?

(related to above) We're starting to approach how context across different
levels of linguistic processing might affect speech recognition.  Based on
these readings, what is the role that context can and cannot play in lexical
access?

How has our understanding of lexical access evolved between the two
readings?  (More detailed understanding of what information matters and how
much, rather than just match/mismatch; expanded scope of study to
segmentation and suprasegmental cues like stress)  What hasn't changed?
("primacy of the signal")
    
*** Plan for class
Want to do a bit more structured stuff...like having pairs come up with
answers to basic content questions, put them in a shared google doc, and
then report back to the whole class.
    
**** themes
interaction between bottom-up and top-down information.  

continuous and probabilistic access and integration.

lexical access sensitive to many many sources of information.

**** activities
***** methods (15 minutes)
make a list of the main methods discussed in these readings.  

***** what's the evidence for parallel activation of word FORMs and MEANINGs (30 minutes)
Form: priming to onset matches; disruption of lexical access when a changed
segment makes another word but not (or less so) for a nonword.  fast access
(close shadowing)

recognition point (based on neighbors); early entry; recognize similar
sounding words based on onsets

Meaning: cross-model priming of onset matches.  involvement of context in
identification before uniqueness point.
     
***** what role does top-down processing play in lexical access? (60 minutes?)
Are there limits?  What is the evidence?

My take: MW argues it plays a /limited role/: shows up in /integration/
processes but not in activation/access/selection.  Evidence for this is:
recognition before uniqueness point, but limited because you don't get
context-specific priming /until uniqueness point/ (context-inconsistent
but form-consistent words are still considered)  (questions about
"activatoin" and "spreading activation" metaphor here)

questions (Ryne and Yarkin): what counts as "top-down"

Sten and Elif: what is lexical access here? (bug example).  WHYYY woudl
you activate the other meanings if you can rule them out???  (uncertainty
about segmentation?  uncertainty about context?)

phonemic restoration?

***** representations: gradient/categorical
compatible with exemplar models?  with "traditional view"?  with
connectionist models like TRACE?

think especially about the findings reviewed in McQueen: importance of
suprasegmental cues, coarticulation, gradedness.

McQueen starts by just assuming that lexical access is mediated by some
kind of sub-lexical categorical representations...how consistent is that
with the results he reviews?

**** Groups from class
Prompt 1: Huteng, Joselyn, Joseph; Ryne, Yarkin; Elif, Sten

** Class 4 - sentence processing
    
*** Readings

**** Tanenhaus and Trueswell

*I think this reading is too hard* - not enough details/examples, too much
literature is reviewed. it's VERY THOROUGH but ... hard to grasp for someone not
already familiar with the paradigms etc.

Contrast is between /constraint based/ vs. /informationally encapsulated/
(modular) theories.

***** History
general arc: language as product (sentence as a linguistic entity) to language
as action (situated in discourse context, produced and interpreted online and
continuously)

Miller - deep structure + transformation tags stored in memory.

***** Current issues

****** Syntactic category ambiguity
multiple access - different senses are activated even in constraining contexts
(but sentence context only weakly constraining), rapidly resolved based on
semantic and syntactic context.  /contingent frequencies/

****** Attachment ambiguity
three families of theories: garden path, referential, and constraint-based.

garden path: Minimal Attachment (simplest possible parse) and Late Closure
(prefer to attach to recent material if equally simple parse)

Referential theories: multiple parses in parallel, selected based on /pragmatic
fit/ with discourse model.  "weakly interactive" (disdcourse model doesn't
affect the generation of parses, but does influence initial selection).  what
/presuppositions/ are required to resolve referring expressions?  syntactic and
presuppositional complexity oftren related (in null context: "the pupil spotted"
read as RC requires presupposing a SET of pupiles, as MV only one)

Constraint-based: underspecified (besides "context/frequency matters"),
frequency hard to compute given lack of large corpora.  lexicalist theories
change that: donate example.  explain reduced relative ambiguity via various
lexical ambiguities (argument structure; tense; voice).  "The horse raced past
the barn fell" vs. "The landmine buried in the sand exploded" (race/bury
frequency in passive/participle/intransitive, agent-ness of horse/landmine)

******* Evidence
disambiguating region: hgiher reading times (first and second pass)

verb-specific syntactic frames ("After the child visited/sneezed the doctor
prescribed...") - rapid filtering of initial parse or constraint based...effects
of frequency (base rate of structure vs. verb-specific bias)

thematic fit/argument assignment: animacy of subject doesn't affect initial
attachment...but they do in more constraining contexts (etc.); and thematic
effects for reduced relatives (stronger for verbs common in passive participle)

referential context: does impact parsing but doesnt' determine it...depends on
sentence local factors that determine the availability of the syntactic
alternatives

prosody and intonation: it matters (phrase boundaries)

****** empty categories
Filler-gap dependencies.  Why?  Because syntactic theories care about them, and
different syntactic theories differ in how they handle them.  Also about
coordinating different kinds of information (for the less ling-y crowd).

Early proposal: filler held in memory until gap is encountered (ERP evidence and
concurrent memory task).  Strong bias to fill first gap that can.

Similar debate: do lexical factors or purely category based factors matter when
determining whether gap filling candidate is good?

Gaps (empty categories) appear to prime like pronouns do (maybe even at the
point the verb is encountered)

****** sentence memory
evidence that there's no verbatim memory even for recent material, "reconstructed
out of lexical representations and their argument structures"

but...priming.

****** context and anaphora
not a separate stage where context-independent meaning is
computed/extracted... rather interpretation happens in the context of a
discourse model shaped by context and continuously updated as new material comes
in.

lots of different linguistics forms taken by anaphors (referring expressions).

"deep" vs. "surface" anaphors (Sag and Hankamer) - hypothesis was that surface
is /linguistic/ representation vs. /conceptual or discourse/ for deep.  (surface
places form constraints, requires linguistically specified antecedent).  but not
much experimental support ... conceptual reference for deep anaphor yes, but
also for surface...

**** van Gompel and Pickering (2007)
both classes are theory are alive and well 10+ years later!  Still work being
done on "revision"

thematic fit is weak (pro-modular) but discourse information is fast
(pro-constraint).

the rest I ... skipped

un-grammatical parses are still stored in memory/affect later parsing?
e.g. kashak and glenburg finding (ungrammatical form gets easier to comprehend);
the thing about changing the baby

*** Questions
What's the advantage of a "garden path" model of online sentence processing?
(Simple rules, informationally encapsulated; theory is more constrained so makes
more specific predictions, vs. constraint-based theories which suffer
underspecification)

How do the three families of theories explain processing difficulty (in
e.g. attachment ambiguity)

Evidence for garden path model?  (Processing difficulty in disambiguating region,
eye movement evidence)

What is the source of difficulty in these models?  (Revision, re-ranking,
conflicting constraints)

One thing that's interesting to me here is the different stakes for the debates
on different sides...like whether semantics can OVERRIDE syntax, or just
influence it quickly.  does semantics CONSTRAIN initial syntactic analysis or
just influence it?

big take away here: there's LOTS OF FACTORS that might affect processing speed
and difficulty, and many of them do matter.  But also many of them are HIGHLY
CORRELATED with each other.  So, what does this tell us about the nature of 1)
language and 2) the language processing system?

what if anything does formal linguistic theory play in our understanding of
sentence processing?

relationship between incremental processing and parallel activation and
ambiguity...do you HAVE to have parallel consideration of multiple
parses/words/etc. when speech comes in online?  If you don't, what kind of
serial processing is compatible with the demands of the continuous input?  what
kind of constraints does the basic 'design principle' of language place on the
processing, and how far can we get just by looking at those constraints?

why is there ambiguity at all?  seems like a bad design choice!

(related: written vs. spoken stimuli, does that bias our understanding?)

What things are /easy/ to explain with a garden path theory, and what things are
/hard/?  What about constraint satisfaction?  What theoretical problems do these
theories /solve/, and what do they /create/?  Garden path theories - solve the
problem of fast, online comprehension (information encapsulation, simple
procedures)...create the problem of how other information gets integrated

*** response papers

**** Ryne
"Kind of fun that you can add components/attachments to your model ad hoc and
everyone’s got different models/principles with names (e.g. Fodor & Frazier
adding Late Closure)." lolololol

**** Joselyn
"what's a sentence and why do we focus on it..."

multiple languages

**** Joseph
modular/interactive - belief updating...reliability of evidence, bias-variance
tradeoff

temporal stuff, does it matter in bayesian updating? 

**** Sten
lexical vs. syntactic ambiguity resolution

no bayes (but foreshadowing??)

*** Learning objectives
Identify the problems these theories are trying to explain (language unfolds
over time and is processed /rapidly/ and /continuously/, but has a
hierarchical/nonlinear structure/"nonadjacent grammatic dependencies" which
leads to /temporary ambiguity/ during processing)

Identify the major empirical /phenomena/ and methods addressed in this work
(high level: "who did what to whom" kind of parsing, (self-paced) reading
time/difficulty/, memory of surface form,

Identify the different theories of syntactic ambiguity resolution:
modular/garden path, interactive/constraint satisfaction, (maybe: discourse
model...what's this called?)

Garden path theory: identify the stages of processing in garden path theories,
and when different kinds of evidence play a role in parsing? (Syntactic category
and grammar, first pass.  Thematic fit/semantics, only on encountering error)

Identify major sources of empirical evidence IN FAVOR of garden path theories,
and AGAINST (reading times slower at disambiguating regions; evidence that
frequency and thematic fit can influence early processing)

Identify the relationship between /linguistic theory/ and /psycholinguistic/
investigation (turn from deep structure to surface structure/clausal
processing, etc.)

Connect the theories of parsing this week with the issues of lexical access we
discussed last week: what role does top-down information play in parsing
according to garden path + constraint satisfaction theories?  When is it
available, and when is it used?  (Garden path model is /kind of/ like the cohort
model...except that cohort model allows ambiguity to be resolved based on top
down information...)

Connect debates in parsing with larger issues of how multiple, correlated
constraints/cues shape processing...does that fact make it EASIER or HARDER to
extract the underlying linguistic structure of the speech stream?  (on the one
hand, it makes it easier because there's many sources of evidence to guide your
interpretation, but harder because they're not all directly/locally linked to
the underlying structure, and they're /weak/ or /probabilistic/ sources of
evidence...)

*** Plan
Same as last week, use breakout rooms and a google doc with prompts for
reflection.  Aim for 3-4 topics/questions to discuss

We have 180 minutes of class time...plan on 20 minutes for break/late start
etc. so that's 160.

**** Prompt 1: theories - 30 minutes (5+10+15)
For modular vs. interactive theories, /what information/ is used to construct the
parse, and /when/ is it used?

- modular: syntactic categories (N/V/Adj/P) + grammatical rules at first (as
  words come in), lexical information/frequency/thematic fit only when the
  initial syntactic parse fails
- interactive: anything and everything...thematic fit (how "agent-y" a noun is),
  subcategorization frames, argument structure, frequency information.  all
  information is /available/, but some information only actually ends up being
  /used/ when there's no stronger cues available (e.g., bottom-up syntactic
  category/grammatical restriction

What is the source of /processing difficulty/ in these theories?

**** Prompt 2: empirical evidence - 45 minutes (0+20+25)
What is the evidence reviewed in the readings that best supports (or supported
at the time) the garden-path theory?  What about constraint-based interactive
theory?  Try to identify 2-3 pieces of evidence for each.

- modular: Joseph (memory for ungrammatical initial), reading times at
  disambiguating region for bad structure
- constraint satisfaction

**** break - 20 minutes

**** Prompt 3: Compare and contrast with lexical access theories - 30 minutes (5+10+15)
Last two weeks we discussed how sounds make contact with linguistic
representations and the lexicon - the "traditional view", connectionist theories
like TRACE, the cohort model, exemplar theory.

Which of these approaches do you see as closest in spirit with the garden-path
theory?  The 'constraint satisfaction' theory?

- garden path: traditional view...strict separation of information sources?
- constraint satisfaction theory: cohort model maybe, but generation of cohort
  is purely bottom-up...but TRACE

I'm hearing...information encapsulation, what's considered when...
**** Prompt 4: Many correlated cues - remainder of class
Again, connect with last week: McQueen especially highlights how many different
sources of information there are in the speech signal to guide lexical access,
cues which people do appear to use.  With the readings this week, we're again
seeing that: there are many overlapping "constraints" or cues which guide the
listener/reader to the correct parse of a sentence (or lead them astray).

What does this fact about the /structure of language/ suggest about the language
processing systems?  E.g., does the existence of such overlapping cues make
processing /easier/ or /harder/ for the system?

What does the empirical evidence about whether (or when) people seem to make use
of different kinds of constraints/cues/information tell us about the nature of
language processing?

**** Prompt 5: what is the role of linguistic theory here?
(I see two places: historical development of psycholinguistic theory/models, and
in identifying linguistically interesting or important phenomena to target with
psycholinguistics, like null anaphor/gapping/ellipsis)

** Class 5 - production

*** Readings

**** Goldrick - Connectionist theories

***** Initial notes
A "generic localist" connectionist network for speech production (word naming),
explains three types of empirical phenomena: mixed errors more common than
expected by chance, semantic interference vs. phonological facilitation, and
impairments.

Then turns to talking about distributed theories, and learning.  Focus on
syntactic priming as implicit learning (Chang et al. , SRN with learning
mechanism), and some kinda oscillator based distributed representation of
sequencing/planning of phonetic segments (lost on me)

***** close reading
mixed errors: explained via two additional mechanisms (cascading activation
and/or feedback)...

disruptions: global vs. local explanations (local wins, global cannot account
for "pure" error distributions, like only semantic)...original global account
has two free parameters: (global) connection weight scaling and (global) decay.
fit to 21 aphasic patients, predict rate of
semantic/phonological/unrelated/non-word errors.

production models *dffer* from connectionist principle in other domains, in two
ways: no learning, and localist representations  (connected: backprop learning
yields distributed hidden layer representations).  two recent developments
1. syntactic priming as implicit learning
2. distributed representations of planning frames using oscillators with learned
   connection weights to phonological structure (interesting that they do not go
   into the problems with the localist representations of words!!)

***** learning objectives
two stages: activation and selection.  why two stages?  what's the role that
each plays?  what's the mechanism for each?  (spreading activation; boosting,
competitoin, or gating)

three empirical findings - what are they and how are they explained in
(localist) connectionist models?
1. semantic interference vs. phonological facilitation
2. mixed errors
3. disruptions/disorders

understand how "classic" connectionist models of production diverge from other
connectionist work (localist, and fixed)
**** Ferreira and Slev - grammatical encoding

***** first read
Talk about "consensus model" where structure and content are planned
separately.  Then talk about debates: separation between selection and
retrieval; whehter content really is planned separately from structure.  Then
more debates: planning scope/incrementality, and syntactic choice.  Then (more)
"emerging" debates: priming, eye movements, storage/memory, disorders.

Close with "fundamental insights": linguistic and non-linguistic knowledge are
different (at some level); "syntax is in there somewhere"

Overall a little light on data for first bit but teh rest is really good.

***** debates
is there really strict separation between *structure* and *content* processing?
"consensus model" says yes...but alternative proposals say no?  Like lexicalized
tree-adjoining grammars, "combinatorial nodes" from pickering

"lexicalized accounts require additional processing machinery to explain
lexically-independent structure-building effects, most especially evidence that
syntactic persistence occurs completely independently of lexical content" -
similar trade-off as with exemplar models: makes some things easier to explain,
but others harder.

**** Meyer and Belke - word form/phonological encoding
Basic distinction: *selection* of lexical unit to produce, *retrieval* of word
form.  why?
- patterns of speech errors: whole word (cross phrases, same syntactic category)
  vs. phonological (same phrase, adjacent/close, different categories).  wider
  planning span at lexical/phonological level than phonetic level
- "tip of the tongue" states (some information about word but can't retrieve
  form); lexical representation has multiple components that have to be
  retrieved by different processes; corroborate by neurlogical case studies
- time course of lexical access: semantic/syntactic is available slightly before
  phonetic. 

serial staged vs. cascaded models (evidence favors cascaded, maybe with
feedback).

but all models agree: separate processes of selection of lemma and retrieval of
form.  this chapter focuses on *word form retrieval*.

rest of the paper: three phases of wordform retrieval: 
1. morphological encoding
2. phonological encoding
3. phonetic encoding

priming studies suggest independent *morphological representations* (with some
questions about derived forms, like ir/regular past tense)

speech errors (and re-syllabification/assimilation/etc.) suggest *phonological
representations* of words too.

things that are not independently planned: very few errors involve /single
phonological features/, but subsitutions/swaps share more features than expected
by chance.  Very few errors of whole syllables moving

interactive (feedback-y) vs. non-interactive models of morpheme-to-phonological
spread...challenge is neighborhood effects: dense neighborhood words easier to
produce.  easy to explain via feedback, harder without (has to go through
*comprehension system* via some monitoring system)

phonetic encoding: go from abstract phonological units to articulatory
gestures.  not a lot of models for this...one is the Levelt and Wheeldon "mental
syllabary"

***** Learning objectives
What's the basic source of evidence for understanding the structure of the
production system?  (speech errors, priming)

connect data on the role that segments play in planning/production with the
abstractionist/exemplar debates in comprehension.

Think about interactive vs. non-interactive theories...how do you explain
"feedback-y" effects (e.g. neighborhood density facilitation) without actually
having feedback?  (monitoring system, comprehension representations)

*** Questions
Each of these papers presents a "consensus model"...what's the relationship
between them?  Where do they agree, and where to do they conflict?  (Ryne
response...)

Relationship between production and perception mechanisms...

*** Learning objectives
Understand the structure/content distinction

Selection/retrieval (access?) distinction

Incremental/staged vs. cascading

Priming/persistence phenomena: What is the phenomenon? Why do they pose a
challenge to the models of production discussed in these readings?  How would
you account for them?



*** Plan for class
God, I dunno.  What actually matters here?
- speech errors as data source
- structure/content
- selection/activation
- priming

**** Prompt 1 - sources of evidence
What are the primary types of behavior/experimental designs that serve as
evidence for understanding production?

**** Prompt 2 - "consensus models"
Each of the chapters we read reviews a "consensus model" of production
('grammatical' encoding, word form encoding, and a generic connectionist
framework).  What are the points where these models agree?  Are there any
disagreements between the different "consensus" models?

(my answers: agree on some degree of separation between selection and
retrieval/access, and separation of different kinds of structural/content
information

** Clsss 6 - discours/pragmatics

*** Questions
Connect with last week...what do these pragmatic/discourse effects suggest about
the architecture of the "message planning" phase of production?
